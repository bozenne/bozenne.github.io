as.data.table(predRR1)[6:7,]
set.seed(10)
predGS <- predict(m.cox_GS, newdata = d, times = 10)
predRR1 <- predictCox(m.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = TRUE)
set.seed(10)
predRR1 <- predictCox(m.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = FALSE)
keep.col <- paste0("survival",c("",".se",".lower",".upper",".lowerBand",".upperBand"))
as.data.table(predRR1)[6:7,]
predRR1$quantile.band[6:7]
set.seed(10)
predRR1 <- predictCox(m.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = TRUE)
predRR1$quantile.band[6:7]
as.data.table(predRR1)[6:7,]
predGS <- predict(m.cox_GS, newdata = d, times = d$eventtime)
predRR1 <- predictCox(m.coxph, newdata = d, times = d$eventtime, se = TRUE, band = TRUE)
predRR2 <- predictCox(m.coxph_d2, newdata = d, times = d$eventtime, se = TRUE, band = TRUE)
predRR1.none <- confint(predRR1, transform.survival = "none", seed = 10)
predRR1.loglog <- confint(predRR1, transform.survival = "loglog", seed = 10)
## punctual estimate
expect_equal(as.double(predRR1$survival), as.double(predGS$S0))
expect_equal(as.double(predRR2$survival), as.double(predGS$S0))
## standard error
expect_equal(as.double(predRR1$survival.se), as.double(predGS$se.S0))
expect_equal(as.double(predRR2$survival.se), as.double(predGS$se.S0))
predGS <- predict(m.cox_GS, newdata = d, times = d$eventtime)
set.seed(10)
predRR1 <- predictCox(m.coxph, newdata = d, times = d$eventtime, se = TRUE, band = TRUE)
as.data.table(predRR1)[6:7,]
predRR1 <- predictCox(m.coxph, newdata = d, times = d$eventtime, se = TRUE, band = TRUE,
log.transform = FALSE)
set.seed(10)
predRR1 <- predictCox(m.coxph, newdata = d, times = d$eventtime, se = TRUE, band = TRUE,
log.transform = FALSE)
as.data.table(predRR1)[6:7,]
predGS <- predict(mI.cox_GS, newdata = d, times = 10)
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE)
as.data.table(    predRR1)[6:7]
set.seed(10)
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE)
as.data.table(    predRR1)[6:7]
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = FALSE)
as.data.table(    predRR1)[6:7]
set.seed(10)
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = FALSE)
as.data.table(    predRR1)[6:7]
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = TRUE)
as.data.table(    predRR1)[6:7]
set.seed(10)
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = TRUE)
as.data.table(    predRR1)[6:7]
predGS <- predict(mI.cox_GS, newdata = d, times = d$eventtime)
set.seed(10)
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = TRUE)
as.data.table(    predRR1)[6:7]
set.seed(10)
predRR1 <- predictCox(mI.coxph, newdata = d, times = 10, se = TRUE, band = TRUE,
log.transform = FALSE)
as.data.table(    predRR1)[6:7]
set.seed(10)
predRR1 <- predictCox(mI.coxph, newdata = d, times = d$eventtime, se = TRUE, band = TRUE,
log.transform = FALSE)
as.data.table(    predRR1)[6:7]
predRR1 <- predictCox(mI.coxph, newdata = d, times = d$eventtime, se = TRUE, band = TRUE,
log.transform = TRUE)
as.data.table(    predRR1)[6:7]
library(gof)
?gof
0.05-1.96*sqrt(0.95*0.05/2e4)
0.05+1.96*sqrt(0.95*0.05/2e4)
library(butils.base)
check = FALSE, install = TRUE)
buildPackage(package = "lava", path = pathGitHub(),
check = TRUE, install = FALSE)
check(force_suggests = FALSE)
test("lava")
run_examples("lava")
## * lavaReduce
# install_github("kkholst/lava")
# install_github("kkholst/lava@fixNR")
buildPackage(package = "lavaReduce", path = pathGitHub(),
check = FALSE, install = TRUE)
buildPackage(package = "lavaReduce", path = pathGitHub(),
check = TRUE, install = FALSE, options.check = "") #   --no-tests --no-examples --no-install
## ** doc
ls.args <- listDocArgs(file.path(pathGitHub(),"lavaReduce"))
# setwd(pathGitHub())
roxygen2::roxygenise("lavaReduce")
test("lavaReduce")
run_examples("lavaReduce")
check_man("lavaReduce")
install_github("kkholst/lava")
library(devtools)
library(butils.base)
library(roxygen2)
library(spelling)
library(devtools)
library(butils.base)
library(roxygen2)
library(spelling)
sessionInfo()
install.packages("BuyseTest")
library(BuyseTest)
?BuyseTest
# reset the default value of the number of permuation sample
BuyseTest.options(method.inference = "none") # no permutation test
#### simulate some data ####
df.data <- simBuyseTest(1e2, n.strata = 2)
BT <- BuyseTest(Treatment ~ TTE(eventtime, censoring = status), data=df.data)
BT <- BuyseTest(Treatment ~ TTE(eventtime, censoring = status), data=df.data, method.inference = "permutation")
summary(BT)
BT <- BuyseTest(Treatment ~ TTE(eventtime, censoring = status), data=df.data, method.inference = "asymptotic")
summary(BT)
confint(BT)
BuyseTest:::confint.BuyseRes
BuyseTest:::confint_Ustatistic
library(survival)
set.seed(10)
d <- sampleData(70,outcome="survival")
d[, X1 := paste0("T",rbinom(.N, size = 2, prob = c(0.51)))]
fit <- coxph(Surv(time,event)~X1 + strata(X2) + X6,
data=d, ties="breslow", x = TRUE, y = TRUE)
fit.pred <- ate(fit, treatment = "X1", times = 1:3, data = d,
se = TRUE, band = TRUE)
library(riskRegression)
library(survival)
set.seed(10)
d <- sampleData(70,outcome="survival")
d[, X1 := paste0("T",rbinom(.N, size = 2, prob = c(0.51)))]
fit <- coxph(Surv(time,event)~X1 + strata(X2) + X6,
data=d, ties="breslow", x = TRUE, y = TRUE)
fit.pred <- ate(fit, treatment = "X1", times = 1:3, data = d,
se = TRUE, band = TRUE)
fit.pred
fit.pred
fit.pred$riskComparison$ratio.se
debug(riskRegression:::calcSeATE)
fit.pred <- ate(fit, treatment = "X1", times = 1:3, data = d,
se = TRUE, band = TRUE)
iid_ratio.contrasts[iiCon, , ]
iid_diff.contrasts[iiCon, , ]
iid_ratio.contrasts[iiCon, , ]
term1
as.numeric(term1)
as.numeric(term2)
ate.iCon/ate.iCon2^2
undebug(riskRegression:::calcSeATE)
fit.pred <- ate(fit, treatment = "X1", times = 1:3, data = d,
se = TRUE, band = TRUE)
print(fit.pred, type = "meanRisk")
library(desc)
library(DescTools)
install.packages("DescTools")
DescTools::FisherZ
DescTools::CorCI
library(devtools)
?use_vignette
?atew
?ate
library(riskRegression)
?ate
n <- 1000
dtS <- sampleData(n, outcome="survival")
dtS$time <- round(dtS$time,1)
dtS$X1 <- factor(rbinom(n, prob = c(0.3,0.4) , size = 2), labels = paste0("T",0:2))
fit <- cph(formula = Surv(time,event)~ X1+X2,data=dtS,y=TRUE,x=TRUE)
library(riskRegression)
library(rms)
set.seed(10)
n <- 1000
dtS <- sampleData(n, outcome="survival")
dtS$time <- round(dtS$time,1)
dtS$X1 <- factor(rbinom(n, prob = c(0.3,0.4) , size = 2), labels = paste0("T",0:2))
fit <- cph(formula = Surv(time,event)~ X1+X2,data=dtS,y=TRUE,x=TRUE)
ateFit1a <- ate(fit, data = dtS, treatment = "X1", times = 5:8,
se = FALSE)
library(riskRegression)
library(rms)
set.seed(10)
n <- 1000
dtS <- sampleData(n, outcome="survival")
dtS$time <- round(dtS$time,1)
dtS$X1 <- factor(rbinom(n, prob = c(0.3,0.4) , size = 2), labels = paste0("T",0:2))
fit <- cph(formula = Surv(time,event)~ X1+X2,data=dtS,y=TRUE,x=TRUE)
ateFit1a <- ate(fit, data = dtS, treatment = "X1", times = 5:8,
se = TRUE, B = 1e2)
ateIID <- ate(fit, data = dtS, treatment = "X1", times = 5:8,
se = TRUE, B = 0)
ateBoot <- ate(fit, data = dtS, treatment = "X1", times = 5:8,
se = TRUE, B = 1e3)
ateBoot
ateIID
24280/3600
devtools::install_github("bozenne/butils")
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE)
devtools::install_github("bozenne/lavaSearch2")
## data management
library(data.table)
## graphical display
library(ggplot2)
## latent variable model
library(lava)
## small sample correction for variable models
library(lava)
library(lavaSearch2) ## devtools::install_github("bozenne/lavaSearch2")
## adjustment for multiple comparisons
library(multcomp)
## qqplots
library(qqtest)
## other
library(butils) ## devtools::install_github("bozenne/butils")
m.sim <- lvm(Y1 ~ 0*X0 + 1*X1 + 1*X2 + 1*eta1,
Y2 ~ 0*X0 + 1*X1 + 2*X2 + 2*eta1,
Y3 ~ 0*X0 + 1*X1 + 1.5*X2 + 3*eta1,
Y4 ~ 0*X0 + 1*X1 + 1.75*X2 + 1*eta1,
Y5 ~ 0*X0 + 1*X1 + 0.75*X2 + 2*eta1,
Y6 ~ 0*X0 + 1*X1 + 0.5*X2 + 3*eta2+eta1,
Y7 ~ 0*X0 + 1*X1 + 0.8*X2 + 1*eta2+eta1,
Y8 ~ 0*X0 + 1*X1 + 1.2*X2 + 2*eta2+eta1,
Y9 ~ 0*X0 + 1*X1 + 1.4*X2 + 0.5*eta2+eta1,
Y10 ~ 0*X0 + 1*X1 + 0.6*X2 + 1*eta2+eta1
)
latent(m.sim) <- ~eta
Sys.getenv("RSTUDIO_PANDOC")
set.seed(10)
dtW <- as.data.table(sim(m.sim, n = 50, latent = FALSE))
head(dtW)
set.seed(10)
dtW <- as.data.table(sim(m.sim, n = 50, latent = FALSE))
head(dtW)
e.lmY1 <- lm(Y1 ~ X0 + X1 + X2)
e.lmY1 <- lm(Y1 ~ X0 + X1 + X2, data = dtW)
## data management
library(data.table)
## graphical display
library(ggplot2)
## latent variable model
library(lava)
## small sample correction for variable models
library(lava)
library(lavaSearch2) ## devtools::install_github("bozenne/lavaSearch2")
## adjustment for multiple comparisons
library(multcomp)
## qqplots
library(qqtest)
## other
library(butils) ## devtools::install_github("bozenne/butils")
library(Publish)
summary(e.lmY1)
publish(e.lmY1)
confint(e.lmY1)
residuals(e.lmY1, type = "Pearson")
residuals(e.lmY1, type = "pearson")
vec.resid <- residuals(e.lmY1, type = "pearson")
qqtest(vec.resid)
source('C:/Users/hpl802/Desktop/mergeInR.R')
source('C:/Users/hpl802/Desktop/mergeInR.R')
df1.small <- df1[1:10,c("CIMBI.ID","scan_id_1")]
df1.small
dfbeta
?dfbeta
library(MCMCglmm)
library(lme4)
library(ggplot2)
library(reshape2)
theme_set(theme_bw())
install.packages("MCMCglmm)
install.packages("MCMCglmm")
library(nlme)
set.seed(102)
n_indiv <- 200
n_per_indiv <- 4
n_tot <- n_indiv * n_per_indiv
id <- gl(n_indiv, n_per_indiv)  ## generate identifier columns
av_wealth <- rlnorm(n_indiv, 0, 1)  ## avg wealth of individuals
ac_wealth <- av_wealth[id] + rlnorm(n_tot, 0, 1)  ## wealth in each year:
av_ratio <- rbeta(n_indiv, 10, 10)  ## 50/50, close to Gaussian
## car/holiday ratio by year (larger shape parameter/less variability)
ac_ratio <- rbeta(n_tot, 2 * av_ratio[id], 2 * (1 - av_ratio[id]))
y.car <- (ac_wealth * ac_ratio)^0.25
y.hol <- (ac_wealth * (1 - ac_ratio))^0.25
Spending <- data.frame(y.hol, y.car, id)
qplot(y.hol, y.car, data = Spending) + geom_smooth(method = "lm")
mSpending
mSpending <- melt(data.frame(Spending, obs = seq(nrow(Spending))), id.var = c("obs",
"id"), variable.name = "trait")
mSpending
table(mSpending$trait,mSpending$id)
Spending
Spending
melt(data.frame(Spending, obs = seq(nrow(Spending))),
id.var = c("obs", "id"), variable.name = "trait")
data.frame(Spending, obs = seq(nrow(Spending)))
set.seed(102)
n_indiv <- 200
n_per_indiv <- 4
n_tot <- n_indiv * n_per_indiv
id <- gl(n_indiv, n_per_indiv)  ## generate identifier columns
av_wealth <- rlnorm(n_indiv, 0, 1)  ## avg wealth of individuals
ac_wealth <- av_wealth[id] + rlnorm(n_tot, 0, 1)  ## wealth in each year:
av_ratio <- rbeta(n_indiv, 10, 10)  ## 50/50, close to Gaussian
## car/holiday ratio by year (larger shape parameter/less variability)
ac_ratio <- rbeta(n_tot, 2 * av_ratio[id], 2 * (1 - av_ratio[id]))
y.car <- (ac_wealth * ac_ratio)^0.25
y.hol <- (ac_wealth * (1 - ac_ratio))^0.25
Spending <- data.frame(y.hol, y.car, id)
qplot(y.hol, y.car, data = Spending) + geom_smooth(method = "lm")
mSpending <- melt(data.frame(Spending, obs = seq(nrow(Spending))),
id.var = c("obs", "id"), variable.name = "trait")
m0 <- lm(y.car ~ y.hol, data = Spending)
Spending
trait
Spending$trait
m1_id <- MCMCglmm(y.car ~ y.hol, random = ~id, data = Spending, verbose = FALSE)
library(MCMCglmm) ## install.packages("MCMCglmm")
m1_id <- MCMCglmm(y.car ~ y.hol, random = ~id, data = Spending, verbose = FALSE)
lme1 <- lme(value ~ trait - 1, random = ~trait - 1 | id, data = mSpending)
lme2 <- update(lme1,
weights = varIdent(form = ~1 | trait),
correlation = corSymm(form = ~1 | id/obs))
VarCorr(lme2)
lme2
mSpending
mSpending[mSpending$id == 1,]
lme2 <- lme(value ~ trait - 1, random = ~trait - 1 | id,
weights = varIdent(form = ~1 | trait),
correlation = corSymm(form = ~1 | id/obs),
data = mSpending)
VarCorr(lme2)
mSpending[mSpending$id == 1,]
mSpending
VarCorr(lme2)
getVarCov(lme2)
gls2 <- gls(value ~ trait - 1,
weights = varIdent(form = ~1 | trait),
correlation = corSymm(form = ~1 | id/obs),
data = mSpending)
gls2
logLik(gls2)
logLik(lme2)
lme1 <- lme(value ~ trait - 1, random = ~trait - 1 | id, data = mSpending)
summary(lme1)
getVarCov(lme1)
?getVarCov
getVarCov(lme1, type = "conditional")
getVarCov(lme1, type = "marginal")
0.0932990* 0.1705054
0.0932990* 0.1979908
getVarCov(lme1, type = "marginal")
0.0932990^2 * 0.1705054
0.0932990^2 * 0.1979908
getVarCov(lme1, type = "conditional")
getVarCov(lme1, type = "marginal")
0.0932990^2
0.1705054^2
0.1979908^2
0.1705054*0.262*0.1979908
logLik(lme1)
lme1 <- lme(value ~ trait, random = ~trait | id, data = mSpending)
logLik(lme1)
getVarCov(lme1, type = "marginal")
summary(lme1)
lme1 <- lme(value ~ trait-1, random = ~trait-1 | id, data = mSpending)
logLik(lme1)
getVarCov(lme1, type = "conditional")
getVarCov(lme1, type = "marginal")
lme2 <- lme(value ~ trait - 1, random = ~trait - 1 | id,
weights = varIdent(form = ~1 | trait),
correlation = corSymm(form = ~1 | id/obs),
data = mSpending)
getVarCov(lme2, type = "conditional")
getVarCov(lme2, type = "conditional")
getVarCov(lme2, type = "marginal")
summary(lme1)
summary(lme2)
logLik(lme1)
logLik(lme2)
summary(lme1)
summary(lme2)
lme2 <- lme(value ~ trait - 1, random = ~trait - 1 | id,
weights = varIdent(form = ~1 | trait),
#correlation = corSymm(form = ~1 | id/obs),
data = mSpending)
getVarCov(lme2, type = "conditional")
getVarCov(lme2, type = "marginal")
summary(lme1)
summary(lme2)
coef(lme2)
logLik(lme1)
logLik(lme2)
lme1 <- lme(value ~ trait-1, random = ~trait-1 | id, data = mSpending)
logLik(lme1)
getVarCov(lme1, type = "conditional")
getVarCov(lme1, type = "marginal")
lme2 <- lme(value ~ trait - 1, random = ~trait - 1 | id,
weights = varIdent(form = ~1 | trait),
data = mSpending)
getVarCov(lme2, type = "conditional")
getVarCov(lme2, type = "marginal")
logLik(lme1)
logLik(lme2)
getVarCov(lme2, type = "conditional")
getVarCov(lme2)
getVarCov(lme1)
VarCorr(lme1)
lme1$modelStruct$reStruct
lme2$modelStruct$varStruct
lme2$modelStruct$reStruct
lme2$modelStruct$varStruct
lme1$modelStruct$varStruct
lme3 <- lme(value ~ trait - 1, random = ~trait - 1 | id,
weights = varIdent(form = ~1 | trait),
correlation = corSymm(form = ~1 | id/obs),
data = mSpending)
lme3$modelStruct$reStruct
lme3$modelStruct$varStruct
lme3$modelStruct$corStruct
getVarCov(lme3, type = "conditional")
getVarCov(lme3, type = "marginal")
summary(lme3)
summary(lme2)
mSpending
?sim
?lava::sim
library(riskRegression)
?ate
library(survival)
library(rms)
set.seed(10)
#### Survival settings  ####
#### ATE with Cox model ####
## generate data
n <- 100
dtS <- sampleData(n, outcome="survival")
dtS$time <- round(dtS$time,1)
dtS$X1 <- factor(rbinom(n, prob = c(0.3,0.4) , size = 2), labels = paste0("T",0:2))
## estimate the Cox model
fit <- cph(formula = Surv(time,event)~ X1+X2,data=dtS,y=TRUE,x=TRUE)
## compute the ATE at times 5, 6, 7, and 8 using X1 as the treatment variable
## Not run:
## only punctual estimate (argument se = FALSE)
ateFit1a <- ate(fit, data = dtS, treatment = "X1", times = 5:8,
se = FALSE)
ateFit1a <- ate(fit, data = dtS, treatment = "X1", times = 5:8,
se = TRUE)
ateFit1a
library(lava)
m <- lvm(Y~E+X1+X2+M,M~E,E~X2)
plot(m, plot.engine="rgraphviz") ## visnetwork ## igraph
plot(m, plot.engine="visnetwork") ## visnetwork ## igraph
plot(m, plot.engine="igraph") ## visnetwork ## igraph
plot(m, plot.engine="visnetwork") ## visnetwork ## igraph
?setwd
library(xlsx)
read.xlsx
write.xlsx
library(gdata)
?gdata
?saveRDS
?pdf
?tiff
library(nlme)
nlme::varConstPower()
?nlme::varConstPower
source('~/GitHub/lavaSearch2/vignettes/script.R')
path <- "C:/Users/hpl802/Documents/GitHub/lavaSearch2/vignettes"
setwd(path)
list.files()
x <- 1
x
mean
getwd()
path <- "C:/Users/hpl802/Documents/GitHub/lavaSearch2/vignettes"
setwd(path)
list.files()
readLines("./mydata.csv")[1:3]
c(1, 2)
c("missing", "NA", " ")
dfW.data <- read.csv("mydata.csv", header = TRUE,
na.strings = c("missing","NA","."), sep = ";", dec = ",")
dfW.data
library(data.table)
library(data.table)
class(dfW.data)
library(data.table)
dtW.data <- as.data.table(dfW.data)
class(dtW.data)
dtW.data
mean(dfW.data$weight_t1)
dtW.data[, mean(weight_t1), by="Treatment"]
dtW.data[, mean(weight_t1), by= c("Gender","Treatment")]
getwd()
getwd()
path <- "C:/Users/hpl802/Documents/GitHub/lavaSearch2/vignettes"
myResult <- dtW.data[, .(weight_t1 = mean(weight_t1)), by="Treatment"]
dtW.data <- as.data.table(dfW.data)
dtW.data[, mean(weight_t1), by= c("Gender","Treatment")]
myResult <- dtW.data[, .(weight_t1 = mean(weight_t1)), by="Treatment"]
myResult
write.csv(myResult, file = "myresult.csv", row.names = FALSE)
library(officer)
my_doc <- read_docx()
my_doc <- body_add_table(x = my_doc, value = myResult)
print(my_doc, target = "myresult.docx")
