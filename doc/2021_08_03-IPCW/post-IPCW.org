#+TITLE: Inverse probability of censoring weighting (IPCW) for linear regression
#+Author: Brice Ozenne

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
path <- "c:/Users/hpl802/Documents/Github/bozenne.github.io/doc/2021_08_03-IPCW/"
setwd(path)
library(nlme)
library(data.table)
library(multcomp)
library(ggplot2)
library(LMMstar)
library(ggpubr)
library(mvtnorm)
library(BuyseTest)
library(survival)
library(riskRegression)
library(mets)
#+END_SRC

#+RESULTS:


* Principle

Inverse probability of censoring weighting (IPCW) is a method able to
handle informative drop-out. Intuitively, in presence of informative
drop-out a complete case analysis is a biased approach as individuals
with complete data are not representative of the population. However
with an appropriate re-weighting of the individuals with complete
data, we can "re-balance" our sample and make it representative of the
population. To do so, we divide the population into sub-populations
and attribute weights to individuals who did not drop-out inversely
proportional to the frequency of the drop-out in the
sub-population. Thanks to the weights, individuals who did not
drop-out "represent" the individuals who dropped-out. Thus, overall,
the weighted sample is representative of the population.

\bigskip

In this document, we will illustrate the use of IPCW:
- with a continuous outcome and compare it with a full information
  approach (via a mixed model).
- with a binary outcome.

\clearpage

* Continuous outcome

** Generative model

To illustrate the use of IPCW in the continuous outcome case, we will
consider a longitudinal study with 2 groups (\(G=0\) and \(G=1\)) and
2 timepoints (\(t_1\) and \(t_2\)) and no other covariate. The outcome
\(Y\) is normally distributed, denoted \(Y_1\) at \(t_1\) and \(Y_2\)
at \(t_2\):
#+BEGIN_EXPORT latex
\begin{align*}
\begin{bmatrix}
Y_1 | G=0 \\ Y_2 |G=0
\end{bmatrix} &= \Gaus\left(
\begin{bmatrix}
50 \\ 50-d\mu_1
\end{bmatrix},100 \begin{bmatrix}
1 & \rho \\ \rho & 1
\end{bmatrix}
\right) \\
\begin{bmatrix}
Y_1 | G=1 \\ Y_2 |G=1
\end{bmatrix} &= \Gaus\left(
\begin{bmatrix}
75 \\ 75-d\mu_2
\end{bmatrix},100 \begin{bmatrix}
1 & \rho \\ \rho & 1
\end{bmatrix}
\right)
\end{align*}
#+END_EXPORT

At time \(t_2\) we may not observed \(Y\) due to drop-out. The
probability of drop-out is either:
- at random with probability \(\pi_C\)
- dependent on a (latent) group: \(\pi_{C_1}\) in \(G=0\) and \(\pi_{C_2}\) in \(G=1\) 
- dependent on the baseline value: \(\frac{1}{1+\exp(-\pi_{C}(Y_1-62.5)/10}\) in \(G=0\) \newline \hphantom{on the basleine value:} \(\frac{1}{1+\exp(-\pi_{C}(Y_1-62.5)/10)}\) in \(G=1\) 

\bigskip

The corresponding R function is given in the next page. It uses the following arguments:
- =n=: [positive integer] number of patient per group
- =rho=: [numeric between -1 and 1] correlation over time
- =dmu=: [numeric vector of length 2] change in mean in each group
- =causeC=: [character] variable defining the censoring probability \newline (either =latent= or =baseline=)
- =piC=: [numeric vector of length 1 or 2, between 0 and 1] parameter(s) for the probability of drop-out.

\clearpage

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
simTrial <- function(n, rho, dmu, causeC, piC){
  ## load packages and check user input
  require(mvtnorm)
  require(data.table)
  causeC <- match.arg(causeC, c("random","baseline","latent"))
  ## simulate data
  sigma <- 10
  Sigma <- sigma^2*matrix(c(1,rho,rho,1),2,2)
  ## gather into dataset
  M.Ym <- rmvnorm(n, mean = c(50, 50-dmu[1]), sigma = Sigma)
  M.Ys <- rmvnorm(n, mean = c(75, 75-dmu[2]), sigma = Sigma)
  dtL <- rbind(
    data.table(id = 1:n, mdd = "moderate", time = "T1", Y = M.Ym[,1]),
    data.table(id = 1:n, mdd = "moderate", time = "T2", Y = M.Ym[,2]),
    data.table(id = n+(1:n), mdd = "severe", time = "T1", Y = M.Ys[,1]),
    data.table(id = n+(1:n), mdd = "severe", time = "T2", Y = M.Ys[,2])
  )
  ## define probability of dropout
  dtL$probaDO <- 0
  if(causeC == "random"){
    dtL[time=="T2", probaDO := piC[1]]
  }else if(causeC == "latent"){
    dtL[time=="T2", probaDO := ifelse(.SD$mdd=="moderate",piC[1],piC[2])]
  }else if(causeC == "baseline"){
    dtL$res <- 0.1 ## no used - just  to initialize
    dtL[mdd=="moderate", res := c((Y[1]-62.5)/sigma,NA), by = "id"]
    dtL[mdd=="severe", res := c((Y[1]-62.5)/sigma,NA), by = "id"]
    dtL[mdd=="moderate", probaDO := c(0,plogis(piC[1]*res[1])), by = "id"]
    dtL[mdd=="severe", probaDO := c(0,plogis(piC[1]*res[1])), by = "id"]
    dtL$res <- NULL
  }
  ## simulate dropout
  dtL[,dropout := rbinom(.N,prob=probaDO,size=1)]
  dtL[,Yobs:=Y]
  dtL[dropout==1,Yobs:=NA]
  ## export
  dtL$probaDO <- NULL
  setkeyv(dtL,"id")
  return(dtL)
}
#+END_SRC

#+RESULTS:

\clearpage

** Illustrative example 1

Consider a study were we follow depressed individual over time. They
have a baseline measurement, then are given a treatment, and then have
a follow-up measurement. We would like to assess the treatment effect
in term of depression score [fn:::To simplify, there is no control
group - we assume that without treatment the depression score would be
constant.]. The population of interest contain severely and moderately
depressed individuals; the treatment may work differently in each
sub-population. Unfortunately, some study participants dropped-out and
it seems that they are more likely to drop-out when their baseline
score is high.

\bigskip

We can simulate such a dataset using the following function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
dtL.B <- simTrial(n = 1000, rho = 0.8, dmu = c(25,50),
                  causeC = "baseline", piC = c(1,1))
head(dtL.B)
#+END_SRC

#+RESULTS:
:    id      mdd time        Y dropout     Yobs
: 1:  1 moderate   T1 49.34367       0 49.34367
: 2:  1 moderate   T2 23.43583       0 23.43583
: 3:  2 moderate   T1 35.05489       0 35.05489
: 4:  2 moderate   T2 13.50810       0 13.50810
: 5:  3 moderate   T1 54.37770       0 54.37770
: 6:  3 moderate   T2 29.80367       1       NA

Here we have simulated a two sub-populations of 1000, with a
correlation of 0.8 between baseline and follow-up. The treatment
effect is twice bigger for the severely depressed population but
individuals from this population are also much more likely to drop-out
as they tend to have higher baseline score. So we expect complete case
estimators to be downward biased.

\bigskip

Without drop-out, we could use a simple linear model to carry-out the
analysis:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.Boracle <- dcast(dtL.B, formula = id ~ time, value.var = "Y")
dtW.Boracle$diff <- dtW.Boracle$T2-dtW.Boracle$T1
e.Boracle <- lm(diff~1, data = dtW.Boracle)
summary(e.Boracle)$coef
#+END_SRC

#+RESULTS:
:              Estimate Std. Error   t value Pr(>|t|)
: (Intercept) -37.34478  0.3131657 -119.2492        0

\clearpage

leading to an estimate quite close to the true value:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
(-25-50)/2
#+END_SRC

#+RESULTS:
: [1] -37.5


With drop-out, a complete case analysis would lead to a biased
estimator. In this example, we can "see" that the estimated value is
far away from the true one (even when accouting for the uncertainty):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.B <- dcast(dtL.B, formula = id + mdd ~ time, value.var = "Yobs")
dtW.B$diff <- dtW.B$T2-dtW.B$T1
dtW.BCC <- dtW.B[!is.na(diff)]
e.BCC <- lm(diff~1, data = dtW.BCC)
summary(e.BCC)$coef
#+END_SRC

#+RESULTS:
:              Estimate Std. Error   t value Pr(>|t|)
: (Intercept) -30.98307  0.3889309 -79.66214        0

An alternative approach would be to use a linear mixed model
(i.e. full information):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
require(nlme)
e.BFI <- lme(Yobs~time, random = ~1|id, data = dtL.B,
             na.action = na.omit)
summary(e.BFI)$tTable
#+END_SRC

#+RESULTS:
:                 Value Std.Error   DF   t-value p-value
: (Intercept)  62.39901 0.3268707 1999 190.89814       0
: timeT2      -34.72137 0.3922177 1030 -88.52576       0
which appears better than the complete case analysis but still
downward biased. This can be a bit surprising at first, but can be
explained when seeing the mixed model as a way to "impute" missing
values at follow-up. The current mixed model is misspecified (missing
interaction between time and group) and it therefore use the wrong
imputation model. This is illustrated in autoref:fig:imputationModel
(see appendix [[#SM:imputation]] for the R code).

\clearpage

#+name: fig:imputationModel
#+ATTR_LaTeX: :width \textwidth :placement [!h]
#+CAPTION: Distribution of the observed and imputed value when using the mixed model.
[[./figures/gg-imputationModel.pdf]]

With a correct model for the outcome (i.e. adding the interaction),
the mixed would be able to impute the observations in an unbiased way:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.BFIoracle <- lme(Yobs~time*mdd, random = ~1|id, data = dtL.B,
                   na.action = na.omit)
summary(e.BFIoracle)$tTable
#+END_SRC

#+RESULTS:
:                      Value Std.Error   DF    t-value       p-value
: (Intercept)       50.14399 0.3201715 1998  156.61602  0.000000e+00
: timeT2           -24.97957 0.2351254 1029 -106.23938  0.000000e+00
: mddsevere         24.51004 0.4527909 1998   54.13102  0.000000e+00
: timeT2:mddsevere -24.90905 0.4443197 1029  -56.06111 4.849765e-315

which would lead to a much better estimator:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(multcomp)
glht(e.BFIoracle, linfct = "timeT2+0.5*timeT2:mddsevere=0")
#+END_SRC

#+RESULTS:
: 
: 	 General Linear Hypotheses
: 
: Linear Hypotheses:
:                                      Estimate
: timeT2 + 0.5 * timeT2:mddsevere == 0   -37.43


\bigskip

An alternative approach that does not require to specify an outcome
model is to use IPCW. It instead requires to correctly specify a model
for the probability of not dropping out at follow-up:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.B$observed <- !is.na(dtW.B$T2)
e.glmW.B <- glm(observed ~ T1, data = dtW.B,
                family = binomial(link = "logit"))
coef(e.glmW.B)
#+END_SRC

#+RESULTS:
: (Intercept)          T1 
:   6.6357425  -0.1047988

and then compute the weights for observations with full data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.B$weight.oracle <- 1/predict(e.glmW.B, newdata = dtW.B,
                                 type = "response")
dtW.B[observed == TRUE, sum(weight.oracle)]
#+END_SRC

#+RESULTS:
: [1] 2045.06

Note that the weights almost sum to the total sample size. We then
perform the complete case analysis with these weights:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.BCC <- dtW.B[!is.na(diff)]
e.BIPCW <- lm(diff~1, data = dtW.BCC, weights = dtW.BCC$weight.oracle)
summary(e.BIPCW)$coef
#+END_SRC

#+RESULTS:
:              Estimate Std. Error   t value Pr(>|t|)
: (Intercept) -37.84241  0.4369635 -86.60314        0

which gives a result very close to the true value. Here the IPCW works
very well because we have specified the correct censoring model.

\clearpage

** Illustrative example 2

Consider a similar study with a different cause of drop-out. This time
drop-out is not due to baseline value but due to the severity of the
disease (i.e. group): two patients severely depressed but with
different baseline score will have exactly the same probability of
drop-out while two patients, one severely depressed and the other
moderately depressed, with same baseline score will have different
probability of drop-out.

\bigskip

We can simulate such a dataset using the following function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
dtL.L <- simTrial(n = 1000, rho = 0.8, dmu = c(25,50),
                  causeC = "latent", piC = c(0.2,0.7))
print(dtL.L)
#+END_SRC

#+RESULTS:
#+begin_example
        id      mdd time        Y dropout     Yobs
   1:    1 moderate   T1 49.34367       0 49.34367
   2:    1 moderate   T2 23.43583       0 23.43583
   3:    2 moderate   T1 35.05489       0 35.05489
   4:    2 moderate   T2 13.50810       0 13.50810
   5:    3 moderate   T1 54.37770       0 54.37770
  ---                                             
3996: 1998   severe   T2 26.26605       1       NA
3997: 1999   severe   T1 70.81751       0 70.81751
3998: 1999   severe   T2 15.46369       1       NA
3999: 2000   severe   T1 73.53750       0 73.53750
4000: 2000   severe   T2 23.75026       1       NA
#+end_example

Overall the expected treatment effect is the same as before and,
without drop-out, the linear model gives the same estimates:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.Loracle <- dcast(dtL.L, formula = id ~ time, value.var = "Y")
dtW.Loracle$diff <- dtW.Loracle$T2-dtW.Loracle$T1
e.Loracle <- lm(diff~1, data = dtW.Loracle)
summary(e.Loracle)$coef
#+END_SRC

#+RESULTS:
:              Estimate Std. Error   t value Pr(>|t|)
: (Intercept) -37.34478  0.3131657 -119.2492        0

\clearpage

With drop-out, a complete case analysis would still lead to a downward
biased estimator:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.L <- dcast(dtL.L, formula = id + mdd ~ time, value.var = "Yobs")
dtW.L$diff <- dtW.L$T2-dtW.L$T1
dtW.LCC <- dtW.L[!is.na(diff)]
e.LCC <- lm(diff~1, data = dtW.LCC)
summary(e.LCC)$coef
#+END_SRC

#+RESULTS:
:              Estimate Std. Error   t value Pr(>|t|)
: (Intercept) -31.47144  0.3853402 -81.67182        0

for a reason similar as before, as patients from the severely
depressed group will drop more often and they benefit more from the
treatmet. We can use a linear mixed model (i.e. full information):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
require(nlme)
e.LFI <- lme(Yobs~time, random = ~1|id, data = dtL.L, na.action = na.omit)
summary(e.LFI)$tTable
#+END_SRC

#+RESULTS:
:                 Value Std.Error   DF   t-value p-value
: (Intercept)  62.39901 0.3216035 1999 194.02463       0
: timeT2      -33.90248 0.3789931 1090 -89.45409       0
which is better than the complete case analysis still biased because
once more the outcome model is misspecified. With a correctly
specified outcome model, we would get a much better estimate:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.LFIoracle <- lme(Yobs~time*mdd, random = ~1|id, data = dtL.L, na.action = na.omit)
glht(e.LFIoracle, linfct = "timeT2+0.5*timeT2:mddsevere=0")

#+END_SRC

#+RESULTS:
: 
: 	 General Linear Hypotheses
: 
: Linear Hypotheses:
:                                      Estimate
: timeT2 + 0.5 * timeT2:mddsevere == 0    -37.3

\bigskip

 When using IPCW, we should model the probability of not dropping out
at follow-up as a function of the latent group:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.L$observed <- !is.na(dtW.L$T2)
e.glmW.Loracle <- glm(observed ~ mdd, data = dtW.L,
                     family = binomial(link = "logit"))
#+END_SRC

#+RESULTS:
and then compute the weights for observations with full data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.L$weight.oracle <- 1/predict(e.glmW.Loracle, newdata = dtW.L,type = "response")
dtW.L[observed == TRUE, sum(weight.oracle)]
#+END_SRC

#+RESULTS:
: [1] 2000

Note that the weights sum to the total sample size. We then perform
the complete case analysis with these weights:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.LCC <- dtW.L[!is.na(diff)]
e.LIPCWoracle <- lm(diff~1, data = dtW.LCC, weights = dtW.LCC$weight.oracle)
summary(e.LIPCWoracle)$coef
#+END_SRC

#+RESULTS:
:              Estimate Std. Error  t value Pr(>|t|)
: (Intercept) -37.35191  0.4242621 -88.0397        0

which gives a result very close to the true value. A more feasible
IPCW would use the baseline score to define the weights:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.glmW.L <- glm(observed ~ T1, data = dtW.L,
              family = binomial(link = "logit"))
dtW.L$weight <- 1/predict(e.glmW.L, newdata = dtW.L, type = "response")
dtW.L[observed == TRUE, sum(weight)]
#+END_SRC

#+RESULTS:
: [1] 2038.825

We then perform the complete case analysis with these new weights:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dtW.LCC <- dtW.L[!is.na(diff)]
e.LIPCW <- lm(diff~1, data = dtW.LCC, weights = dtW.LCC$weight)
summary(e.LIPCW)$coef
#+END_SRC

#+RESULTS:
:             Estimate Std. Error   t value Pr(>|t|)
: (Intercept) -36.0517  0.4258783 -84.65258        0

\clearpage

** Simulation study

The quality of the previous estimators is compared using a simulation
study. The results are summarized by autoref:fig:simulationGaussian.

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
  warper <- function(n, rho, dmu, causeC, piC){
    require(multcomp)

    ## *** simulate data
    dtL <- simTrial(n = n, rho = rho, dmu = dmu, causeC = causeC, piC = piC)

    ## *** rehape data
    dtW <- dcast(dtL, formula = id + mdd ~ time, value.var = "Yobs")
    dtW$diff <- dtW$T2-dtW$T1
    dtW$observed <- 1-is.na(dtW$T2)

    dtW.oracle <- dcast(dtL, formula = id ~ time, value.var = "Y")
    dtW.oracle$diff <- dtW.oracle$T2-dtW.oracle$T1

    ## *** oracle
    e.lmOracle <- lm(diff~1, data = dtW.oracle)

    ## *** naive and biased analysis
    e.lmNaive <- lm(diff~1, data = dtW)

    ## *** oracle mixed model
    e.lme.oracle <- lme(Yobs~time*mdd, random = ~1|id, data = dtL, na.action = na.omit)

    ## *** mixed model
    e.lme <- lme(Yobs~time, random = ~1|id, data = dtL, na.action = na.omit)

    ## *** IPCW with oracle weights
    if(causeC=="random"){
      e.glmW.oracle <- glm(observed ~ 1, data = dtW, family = binomial(link = "logit"))
      dtW$weight.oracle <- 1/predict(e.glmW.oracle, newdata = dtW, type = "response")
      e.lmIPCW.oracle <- lm(diff~1, data = dtW[observed == 1], weights = dtW[observed == 1,weight.oracle])
    }else if(causeC=="latent"){
      e.glmW.oracle <- glm(observed ~ mdd, data = dtW, family = binomial(link = "logit"))
      dtW$weight.oracle <- 1/predict(e.glmW.oracle, newdata = dtW, type = "response")
      e.lmIPCW.oracle <- lm(diff~1, data = dtW[observed == 1], weights = dtW[observed == 1,weight.oracle])
    }else if(causeC=="baseline"){
      e.glmW.oracle <- glm(observed ~ T1, data = dtW, family = binomial(link = "logit"))
      dtW$weight.oracle <- 1/predict(e.glmW.oracle, newdata = dtW, type = "response")
      e.lmIPCW.oracle <- lm(diff~1, data = dtW[observed == 1], weights = dtW[observed == 1,weight.oracle])
    }

    ## *** IPCW with feasible weights
    if(causeC=="latent"){
      e.glmW <- glm(observed ~ T1, data = dtW, family = binomial(link = "logit"))
      dtW$weight <- 1/predict(e.glmW, newdata = dtW, type = "response")
      e.lmIPCW <- lm(diff~1, data = dtW[observed == 1], weights = dtW[observed == 1,weight])
    }

    ## *** export
    res.oracle <- setNames(summary(e.lmOracle)$coef["(Intercept)",], c("estimate","se","statistic","p.value"))
    res.naive <- setNames(summary(e.lmNaive)$coef["(Intercept)",], c("estimate","se","statistic","p.value"))
    res.lme.oracle <- setNames(as.double(summary(glht(e.lme.oracle, linfct = "timeT2+0.5*timeT2:mddsevere=0"))$test[c("coefficients","sigma","tstat","pvalues")]),
                               c("estimate","se","statistic","p.value"))
    res.lme <- setNames(summary(e.lme)$tTable["timeT2",c(1:2,4:5)], c("estimate","se","statistic","p.value"))
    res.IPCW.oracle <- setNames(summary(e.lmIPCW.oracle)$coef["(Intercept)",], c("estimate","se","statistic","p.value"))
    out <- rbind(cbind(model = "oracle", rho = rho, n = n, dmu = diff(dmu), as.data.frame(as.list(res.oracle))),
                 cbind(model = "complete case", rho = rho, n = n, dmu = diff(dmu), as.data.frame(as.list(res.naive))),
                 cbind(model = "FI.oracle", rho = rho, n = n, dmu = diff(dmu), as.data.frame(as.list(res.lme.oracle))),
                 cbind(model = "FI", rho = rho, n = n, dmu = diff(dmu), as.data.frame(as.list(res.lme))),
                 cbind(model = "IPCW.oracle", rho = rho, n = n, dmu = diff(dmu), as.data.frame(as.list(res.IPCW.oracle)))
                 )
    if(causeC=="latent"){
      res.IPCW <- setNames(summary(e.lmIPCW)$coef[1,], c("estimate","se","statistic","p.value"))
      out <- rbind(out,
                   cbind(model = "IPCW", rho = rho, n = n, dmu = diff(dmu), as.data.frame(as.list(res.IPCW)))
                   )
    }
    return(cbind(out,causeC=causeC))
  }
#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
## Sanity check
set.seed(10)
warper(n = 1000, rho = 0.8, dmu = c(25,50), causeC = "random", piC = 0.5)
set.seed(10)
warper(n = 1000, rho = 0.8, dmu = c(25,50), causeC = "baseline", piC = 1)
set.seed(10)
warper(n = 1000, rho = 0.8, dmu = c(25,50), causeC = "latent", piC = c(0.2,0.7))
#+END_SRC

#+RESULTS:
#+begin_example
          model rho    n dmu  estimate        se  statistic p.value causeC
1        oracle 0.8 1000  25 -37.34478 0.3131657 -119.24924       0 random
2 complete case 0.8 1000  25 -37.60385 0.4396445  -85.53240       0 random
3     FI.oracle 0.8 1000  25 -37.47880 0.1997909 -187.59011       0 random
4            FI 0.8 1000  25 -37.65209 0.4239748  -88.80738       0 random
5   IPCW.oracle 0.8 1000  25 -37.60385 0.4396445  -85.53240       0 random
          model rho    n dmu  estimate        se  statistic p.value   causeC
1        oracle 0.8 1000  25 -37.34478 0.3131657 -119.24924       0 baseline
2 complete case 0.8 1000  25 -30.98307 0.3889309  -79.66214       0 baseline
3     FI.oracle 0.8 1000  25 -37.43410 0.2221598 -168.50074       0 baseline
4            FI 0.8 1000  25 -34.72137 0.3922177  -88.52576       0 baseline
5   IPCW.oracle 0.8 1000  25 -37.84241 0.4369635  -86.60314       0 baseline
          model rho    n dmu  estimate        se  statistic p.value causeC
1        oracle 0.8 1000  25 -37.34478 0.3131657 -119.24924       0 latent
2 complete case 0.8 1000  25 -31.47144 0.3853402  -81.67182       0 latent
3     FI.oracle 0.8 1000  25 -37.30128 0.2145794 -173.83442       0 latent
4            FI 0.8 1000  25 -33.90248 0.3789931  -89.45409       0 latent
5   IPCW.oracle 0.8 1000  25 -37.35191 0.4242621  -88.03970       0 latent
6          IPCW 0.8 1000  25 -36.05170 0.4258783  -84.65258       0 latent
#+end_example


#+BEGIN_SRC R :exports none :results output :session *R* :cache no
n.sim <- 100
ls.res <- lapply(1:n.sim, function(iSim){
  out <- try(rbind(warper(n = 1000, rho = 0, dmu = c(25,40), causeC = "random", piC = 0.5),
                   warper(n = 1000, rho = 0.25, dmu = c(25,40), causeC = "random", piC = 0.5),
                   warper(n = 1000, rho = 0.5, dmu = c(25,40), causeC = "random", piC = 0.5),
                   warper(n = 1000, rho = 0.8, dmu = c(25,40), causeC = "random", piC = 0.5),
                   warper(n = 1000, rho = 0, dmu = c(25,40), causeC = "baseline", piC = 1),
                   warper(n = 1000, rho = 0.25, dmu = c(25,40), causeC = "baseline", piC = 1),
                   warper(n = 1000, rho = 0.5, dmu = c(25,40), causeC = "baseline", piC = 1),
                   warper(n = 1000, rho = 0.8, dmu = c(25,40), causeC = "baseline", piC = 1),
                   warper(n = 1000, rho = 0, dmu = c(25,40), causeC = "latent", piC = c(0.2,0.7)),
                   warper(n = 1000, rho = 0.25, dmu = c(25,40), causeC = "latent", piC = c(0.2,0.7)),
                   warper(n = 1000, rho = 0.5, dmu = c(25,40), causeC = "latent", piC = c(0.2,0.7)),
                   warper(n = 1000, rho = 0.8, dmu = c(25,40), causeC = "latent", piC = c(0.2,0.7))))
  if(inherits(out,"try-error")){
    return(NULL)
  }else{
    return(out)
  }
})
#+END_SRC

#+RESULTS:
#+begin_example
Error in lme.formula(Yobs ~ time * mdd, random = ~1 | id, data = dtL,  : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time * mdd, random = ~1 | id, data = dtL,  : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time * mdd, random = ~1 | id, data = dtL,  : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time * mdd, random = ~1 | id, data = dtL,  : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
Error in lme.formula(Yobs ~ time, random = ~1 | id, data = dtL, na.action = na.omit) : 
  nlminb problem, convergence error code = 1
  message = false convergence (8)
#+end_example

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
library(ggplot2)
library(data.table)
dt.res <- as.data.table(do.call(rbind,ls.res))
dt.res[, estimator := factor(model, c("complete case","FI","FI.oracle","IPCW","IPCW.oracle","oracle"))]
dt.res[, correlation := paste0("correlation = ", rho)]
dt.res[, cause := factor(causeC,
                         levels = c("random","baseline","latent"),
                         labels = c("cause of dropout: random", "cause of dropout: baseline score","cause of dropout: latent group"))]

gg <- ggplot(dt.res, aes(y = estimate))
gg <- gg + geom_boxplot(aes(fill=estimator))
gg <- gg + facet_grid(cause~correlation)
gg <- gg + theme(axis.title.x=element_blank(),
                 axis.text.x=element_blank(),
                 axis.ticks.x=element_blank())
gg <- gg + theme(text = element_text(size=15),
                 axis.line = element_line(size = 1.25),
                 axis.ticks = element_line(size = 2),
                 axis.ticks.length=unit(.25, "cm"),
                 legend.position="bottom",
                 legend.direction = "horizontal")
ggsave(gg, filename = "./figures/simStudy-bias.pdf", width = 8.5)
#+END_SRC

#+RESULTS:
: Saving 8.5 x 10.4 in image

#+name: fig:simulationGaussian
#+ATTR_LaTeX: :width \textwidth :placement [!h]
#+CAPTION: Comparison between the empirical distributions of the estimators (Gaussian case) for a sample size of 1000 using 100 datasets.
#+CAPTION: FI: full information (random intercept model), IPCW: inverse probability of censoring weights.
[[./figures/simStudy-bias.pdf]]

\clearpage

* Binary outcome

** Illustrative example
A somehow similar approach can be used for binary endpoints. Consider
now a study comparing the survival probability at 1 year of patients
treated with a new drug vs. standard care. The population is composed
of two types of patients, say some with hypertension and some
without. Survival as well as the treatment effect may differ depending
of the hypertension status. Hypertension may also affect the drop-out
probability.

\bigskip

We can simulate such a dataset using the following function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
simTrial <- function(n, dmu, dpC){
  require(BuyseTest)
  require(data.table)
  ## simulate data
  dt1  <- simBuyseTest(n.T = n, n.C = n, 
                       argsBin = NULL, argsCont = NULL, 
                       argsTTE = list(scale.T = 1+dmu[1],
                                      scale.C = 1,
                                      scale.censoring.T = 1+dpC[1],
                                      scale.censoring.C = 1),
                       latent = TRUE)
  dt2  <- simBuyseTest(n.T = n, n.C = n, 
                       argsBin = NULL, argsCont = NULL, 
                       argsTTE = list(scale.T = 2+dmu[2],
                                      scale.C = 2,
                                      scale.censoring.T = 2+dpC[2],
                                      scale.censoring.C = 2),
                       latent = TRUE)
  ## gather into dataset
  dt <- rbind(
    cbind(id = 1:NROW(dt1), group = "G1", dt1),
    cbind(id = NROW(dt1) + 1:NROW(dt2), group = "G2", dt2)
  )
  return(dt)
}
#+END_SRC

#+RESULTS:

\clearpage

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(11)
tau <- 1

dt <- simTrial(n = 1000, dmu = c(0,1), dpC = c(0,1))
dt$responseUncensored <- dt$eventtimeUncensored<=tau
dt$response <- ifelse((dt$status==1)+(dt$eventtime>tau),dt$eventtime<=tau,NA)
dt$observed <- ifelse((dt$status==1)+(dt$eventtime>tau),1,0)
print(dt)
#+END_SRC

#+RESULTS:
#+begin_example
        id group treatment eventtimeUncensored eventtimeCensoring  eventtime
   1:    1    G1         C          0.07747187          0.4441963 0.07747187
   2:    2    G1         C          0.18271259          0.3567996 0.18271259
   3:    3    G1         C          0.14864417          0.2298933 0.14864417
   4:    4    G1         C          0.26922419          0.6492349 0.26922419
   5:    5    G1         C          0.52950600          0.2238334 0.22383343
  ---                                                                       
3996: 3996    G2         T          1.09150744          5.6892558 1.09150744
3997: 3997    G2         T          5.83550031          1.7693238 1.76932381
3998: 3998    G2         T          0.88964585          0.2485173 0.24851729
3999: 3999    G2         T          0.44492756          4.8949421 0.44492756
4000: 4000    G2         T         18.10666952          2.5876528 2.58765282
      status responseUncensored response observed
   1:      1               TRUE     TRUE        1
   2:      1               TRUE     TRUE        1
   3:      1               TRUE     TRUE        1
   4:      1               TRUE     TRUE        1
   5:      0               TRUE       NA        0
  ---                                            
3996:      1              FALSE    FALSE        1
3997:      0              FALSE    FALSE        1
3998:      0               TRUE       NA        0
3999:      1               TRUE     TRUE        1
4000:      0              FALSE    FALSE        1
#+end_example

\clearpage

In absence of drop-out, we can compare the survival
probabilities at 1 year using a logistic regression:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.oracle <- glm(responseUncensored ~ treatment,
                data = dt, family = binomial(link="logit"))
summary(e.oracle)$coef
#+END_SRC

#+RESULTS:
:                Estimate Std. Error   z value     Pr(>|z|)
: (Intercept)  0.08204599 0.04475899  1.833062 6.679338e-02
: treatmentT  -0.27060267 0.06341278 -4.267321 1.978345e-05

In presence of (differential) drop-out, a complete case analysis
(i.e. restricting the analysis to the patients where the survival
status at 1 year is known) would be biased:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dt.cc <- dt[dt$observed==1]
e.cc <- glm(response ~ treatment,
            data = dt.cc, family = binomial(link="logit"))
summary(e.cc)$coef
#+END_SRC

#+RESULTS:
:               Estimate Std. Error   z value     Pr(>|z|)
: (Intercept)  0.4008704 0.05727500  6.999047 2.577101e-12
: treatmentT  -0.4222127 0.07955849 -5.306947 1.114767e-07

A first idea would be to re-use the IPCW approach, first fitting a
logistic model for the probability of being observed at 1-year and
then computing the weights:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.IPCmodel <- glm(observed ~ group*treatment, data = dt, family = binomial(link="logit"))
dt$IPCweights <- 1/predict(e.IPCmodel, newdata = dt, type = "response")
sum(dt$IPCweights)
#+END_SRC

#+RESULTS:
: [1] 6305.334

The subsequent estimator will not be correct: 
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dt.cc <- dt[dt$observed==1]
e.IPCWcc <- glm(response ~ treatment, data = dt.cc,
                family = binomial(link="logit"), weights = dt.cc$IPCweights)
summary(e.IPCWcc)$coef
#+END_SRC

#+RESULTS:
: Advarselsbesked:
: I eval(family$initialize) : non-integer #successes in a binomial glm!
:               Estimate Std. Error   z value     Pr(>|z|)
: (Intercept)  0.4515849 0.04586621  9.845700 7.153939e-23
: treatmentT  -0.3341242 0.06411408 -5.211402 1.874189e-07

as we disregarded the duration of observation among the censored
individuals. Intuitively, individuals censored early are more at risk
of dying and therefore should "transfer" more weight than those
censored late, e.g. just before 1 year, who don't really need to
transfer weights. This can be perform using a survival model (here a
Cox model) and using as weights the inverse of the probability of not
being censored at the earliest between when the event occured and 1
year:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(survival)
library(riskRegression)
e.IPCmodel2 <- coxph(Surv(eventtime,status==0) ~ group*treatment,
                     data = dt, x = TRUE, y = TRUE)
iPred <- predictCox(e.IPCmodel2, newdata = dt,
                    time = pmin(dt$eventtime,tau)-(1e-12), diag = TRUE)$survival
dt$IPCweights2 <- dt$observed/iPred
sum(dt$IPCweights2)
#+END_SRC

#+RESULTS:
: [1] 3997.757

We can then use the weights in a logistic model:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
dt.cc <- dt[dt$observed==1]
e.IPCWcc <- glm(response ~ treatment, data = dt.cc,
                family = quasibinomial(link="logit"), weights = dt.cc$IPCweights2)
summary(e.IPCWcc)$coef
#+END_SRC

#+RESULTS:
:                Estimate Std. Error    t value     Pr(>|t|)
: (Intercept)  0.04110777 0.05561028  0.7392117 0.4598457572
: treatmentT  -0.26472454 0.07902160 -3.3500276 0.0008196644

which is very close to the true value.

\clearpage

Note that this estimator is implemented in the riskRegression package:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.wglm <- wglm(regressor.event = ~treatment,
               formula.censor = Surv(eventtime,status==0)~group*treatment,
               times = 1, 
               data = dt[,.(eventtime,status,group,treatment)])
summary(e.wglm)
#+END_SRC

#+RESULTS:
#+begin_example
     IPCW logistic regression : 
----------------------------------------------------------------------------------
  - time: 1
glm(XX_status.1_XX ~ treatment, family = binomial(link = "logit"), 
    weights = "XX_IPCW.1_XX")

               Estimate Std. Error    z value    Pr(>|z|)
(Intercept)  0.04110777 0.05672432  0.7246939 0.468639833
treatmentT  -0.26472454 0.08136191 -3.2536668 0.001139258
----------------------------------------------------------------------------------
#+end_example

This estimator is also implemented in the =mets= package[fn::the standard errors are slightly different though]:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(mets)
e.mets <- logitIPCW(formula = Event(eventtime,status) ~ treatment,
                    cens.model = ~group*treatment,
                    time = 1, data = dt, cens.code = 0, cause = 1)
e.mets
#+END_SRC

#+RESULTS:
#+begin_example

    n events
 4000   1409

 4000 clusters
coeffients:
             Estimate   Std.Err      2.5%     97.5% P-value
(Intercept)  0.041108  0.056878 -0.070371  0.152587  0.4698
treatmentT  -0.264725  0.082562 -0.426543 -0.102906  0.0013

exp(coeffients):
            Estimate    2.5%  97.5%
(Intercept)  1.04196 0.93205 1.1648
treatmentT   0.76742 0.65276 0.9022
#+end_example

#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
ls.sim <- lapply(1:1000,function(i){
  dt <- simTrial(n = 1000, dmu = c(0,1), dpC = c(0,1))
  e.wglm <- wglm(regressor.event = ~treatment,
                 formula.censor = Surv(eventtime,status==0)~group*treatment,
                 times = 1, 
                 data = dt[,.(eventtime,status,group,treatment)])
  coef(e.wglm)
})
#+END_SRC

#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
var(do.call(rbind,ls.sim))-vcov(e.mets)
var(do.call(rbind,ls.sim))-crossprod(iid(e.wglm))
#+END_SRC
#+RESULTS:
:results:
              (Intercept)   treatmentT
(Intercept) -5.162353e-06  9.88919e-05
treatmentT   9.889190e-05 -3.92990e-04
              (Intercept)    treatmentT
(Intercept)  1.231973e-05 -5.269787e-05
treatmentT  -5.269787e-05 -1.962764e-04
:end:


** Simulation study

The quality of the previous estimators is compared using a simulation
study. The results are summarized by autoref:fig:simulationBinary.
#+name: fig:simulationBinary
#+ATTR_LaTeX: :width \textwidth :placement [!h]
#+CAPTION: Comparison between the empirical distributions of the estimators (binary case) 
#+CAPTION: across sample size. Based on 1000 replicates.
[[./figures/simStudy-bin-bias.pdf]]


#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
warper <- function(n, dmu, dpC, tau){

    ## simulate data
    dt <- simTrial(n = n, dmu = dmu, dpC = dpC)
    dt$responseUncensored <- dt$eventtimeUncensored<=tau
    dt$response <- ifelse((dt$status==1)+(dt$eventtime>tau),dt$eventtime<=tau,NA)
    dt$observed <- ifelse((dt$status==1)+(dt$eventtime>tau),1,0)

    ## oracle estimator
    e.oracle <- glm(responseUncensored ~ treatment, data = dt, family = binomial(link="logit"))

    ## complete case estimator
    dt.cc <- dt[dt$observed==1]
    e.cc <- glm(response ~ treatment, data = dt.cc, family = binomial(link="logit"))

    ## IPCW version 1
    e.IPCmodel <- glm(observed ~ group*treatment, data = dt, family = binomial(link="logit"))
    dt$IPCweights <- 1/predict(e.IPCmodel, newdata = dt, type = "response")
    dt.cc <- dt[dt$observed==1]
    e.IPCWglm <- suppressWarnings(glm(response ~ treatment, data = dt.cc, family = binomial(link="logit"), weights = dt.cc$IPCweights))

    ## IPCW version 2
    e.IPCWcox <- wglm(regressor.event = ~treatment,
                      formula.censor = Surv(eventtime,status==0)~group*treatment,
                      times = 1,
                      data = dt[,.(eventtime,status,group,treatment)])

    ## IPCW mets
    e.mets <- logitIPCW(formula = Event(eventtime,status) ~ treatment,
                        cens.model = ~group*treatment,
                        time = 1, data = dt, cens.code = 0, cause = 1)

    ## assemble
    res.oracle <- setNames(summary(e.oracle)$coef["treatmentT",c(1:2,4)], c("estimate","sd","p.value"))
    res.cc <- setNames(summary(e.cc)$coef["treatmentT",c(1:2,4)], c("estimate","sd","p.value"))
    res.IPCWglm <- setNames(summary(e.IPCWglm)$coef["treatmentT",c(1:2,4)], c("estimate","sd","p.value"))
    res.IPCWcox <- setNames(summary(e.IPCWcox, print = FALSE)[[1]]["treatmentT",c(1:2,4)], c("estimate","sd","p.value"))
    res.mets <- setNames(summary(e.mets)$coef["treatmentT",c(1:2,5)], c("estimate","sd","p.value"))
    
    out <- rbind(cbind(estimator = "oracle", as.data.frame(as.list(res.oracle))),
                 cbind(estimator = "cc", as.data.frame(as.list(res.cc))),
                 cbind(estimator = "IPCWglm", as.data.frame(as.list(res.IPCWglm))),
                 cbind(estimator = "IPCWcox", as.data.frame(as.list(res.IPCWcox))),
                 cbind(estimator = "mets", as.data.frame(as.list(res.mets))))
    ##
    return(cbind(n=n,tau=tau,out))
}
#+END_SRC

#+RESULTS:
:results:
:end:

#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
## Sanity check
set.seed(11)
warper(n = 1000, dmu = c(0,1), dpC = c(0,1), tau = 1)
#+END_SRC

#+RESULTS:
:results:
     n tau estimator   estimate         sd      p.value
1 1000   1    oracle -0.2706027 0.06341278 1.978345e-05
2 1000   1        cc -0.4222127 0.07955849 1.114767e-07
3 1000   1   IPCWglm -0.3341242 0.06411408 1.874189e-07
4 1000   1   IPCWcox -0.2647245 0.08136191 1.139258e-03
5 1000   1      mets -0.2647245 0.08256194 1.344187e-03
:end:

#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
library(pbapply)
n.sim <- 100
ls.res <- pblapply(1:n.sim, function(iSim){
  rbind(warper(n = 100, dmu = c(0,1), dpC = c(0,1), tau = 1),
        warper(n = 500, dmu = c(0,1), dpC = c(0,1), tau = 1),
        warper(n = 1000, dmu = c(0,1), dpC = c(0,1), tau = 1))
})
#+END_SRC

#+RESULTS:
:results:
  |                                                  | 0 % ~calculating    |+                                                 | 1 % ~03m 23s        |+                                                 | 2 % ~03m 19s        |++                                                | 3 % ~03m 16s        |++                                                | 4 % ~03m 13s        |+++                                               | 5 % ~03m 11s        |+++                                               | 6 % ~03m 09s        |++++                                              | 7 % ~03m 07s        |++++                                              | 8 % ~03m 05s        |+++++                                             | 9 % ~03m 03s        |+++++                                             | 10% ~03m 01s        |++++++                                            | 11% ~02m 59s        |++++++                                            | 12% ~02m 56s        |+++++++                                           | 13% ~02m 54s        |+++++++                                           | 14% ~02m 52s        |++++++++                                          | 15% ~02m 51s        |++++++++                                          | 16% ~02m 49s        |+++++++++                                         | 17% ~02m 47s        |+++++++++                                         | 18% ~02m 44s        |++++++++++                                        | 19% ~02m 43s        |++++++++++                                        | 20% ~02m 41s        |+++++++++++                                       | 21% ~02m 39s        |+++++++++++                                       | 22% ~02m 37s        |++++++++++++                                      | 23% ~02m 35s        |++++++++++++                                      | 24% ~02m 33s        |+++++++++++++                                     | 25% ~02m 31s        |+++++++++++++                                     | 26% ~02m 29s        |++++++++++++++                                    | 27% ~02m 27s        |++++++++++++++                                    | 28% ~02m 25s        |+++++++++++++++                                   | 29% ~02m 23s        |+++++++++++++++                                   | 30% ~02m 21s        |++++++++++++++++                                  | 31% ~02m 19s        |++++++++++++++++                                  | 32% ~02m 17s        |+++++++++++++++++                                 | 33% ~02m 15s        |+++++++++++++++++                                 | 34% ~02m 13s        |++++++++++++++++++                                | 35% ~02m 11s        |++++++++++++++++++                                | 36% ~02m 09s        |+++++++++++++++++++                               | 37% ~02m 07s        |+++++++++++++++++++                               | 38% ~02m 05s        |++++++++++++++++++++                              | 39% ~02m 03s        |++++++++++++++++++++                              | 40% ~02m 01s        |+++++++++++++++++++++                             | 41% ~01m 59s        |+++++++++++++++++++++                             | 42% ~01m 57s        |++++++++++++++++++++++                            | 43% ~01m 55s        |++++++++++++++++++++++                            | 44% ~01m 53s        |+++++++++++++++++++++++                           | 45% ~01m 51s        |+++++++++++++++++++++++                           | 46% ~01m 49s        |++++++++++++++++++++++++                          | 47% ~01m 47s        |++++++++++++++++++++++++                          | 48% ~01m 45s        |+++++++++++++++++++++++++                         | 49% ~01m 43s        |+++++++++++++++++++++++++                         | 50% ~01m 41s        |++++++++++++++++++++++++++                        | 51% ~01m 40s        |++++++++++++++++++++++++++                        | 52% ~01m 38s        |+++++++++++++++++++++++++++                       | 53% ~01m 35s        |+++++++++++++++++++++++++++                       | 54% ~01m 33s        |++++++++++++++++++++++++++++                      | 55% ~01m 31s        |++++++++++++++++++++++++++++                      | 56% ~01m 29s        |+++++++++++++++++++++++++++++                     | 57% ~01m 27s        |+++++++++++++++++++++++++++++                     | 58% ~01m 25s        |++++++++++++++++++++++++++++++                    | 59% ~01m 23s        |++++++++++++++++++++++++++++++                    | 60% ~01m 21s        |+++++++++++++++++++++++++++++++                   | 61% ~01m 19s        |+++++++++++++++++++++++++++++++                   | 62% ~01m 17s        |++++++++++++++++++++++++++++++++                  | 63% ~01m 15s        |++++++++++++++++++++++++++++++++                  | 64% ~01m 13s        |+++++++++++++++++++++++++++++++++                 | 65% ~01m 11s        |+++++++++++++++++++++++++++++++++                 | 66% ~01m 09s        |++++++++++++++++++++++++++++++++++                | 67% ~01m 07s        |++++++++++++++++++++++++++++++++++                | 68% ~01m 05s        |+++++++++++++++++++++++++++++++++++               | 69% ~01m 03s        |+++++++++++++++++++++++++++++++++++               | 70% ~01m 01s        |++++++++++++++++++++++++++++++++++++              | 71% ~59s            |++++++++++++++++++++++++++++++++++++              | 72% ~57s            |+++++++++++++++++++++++++++++++++++++             | 73% ~55s            |+++++++++++++++++++++++++++++++++++++             | 74% ~53s            |++++++++++++++++++++++++++++++++++++++            | 75% ~51s            |++++++++++++++++++++++++++++++++++++++            | 76% ~49s            |+++++++++++++++++++++++++++++++++++++++           | 77% ~47s            |+++++++++++++++++++++++++++++++++++++++           | 78% ~45s            |++++++++++++++++++++++++++++++++++++++++          | 79% ~43s            |++++++++++++++++++++++++++++++++++++++++          | 80% ~41s            |+++++++++++++++++++++++++++++++++++++++++         | 81% ~39s            |+++++++++++++++++++++++++++++++++++++++++         | 82% ~37s            |++++++++++++++++++++++++++++++++++++++++++        | 83% ~35s            |++++++++++++++++++++++++++++++++++++++++++        | 84% ~33s            |+++++++++++++++++++++++++++++++++++++++++++       | 85% ~31s            |+++++++++++++++++++++++++++++++++++++++++++       | 86% ~29s            |++++++++++++++++++++++++++++++++++++++++++++      | 87% ~27s            |++++++++++++++++++++++++++++++++++++++++++++      | 88% ~24s            |+++++++++++++++++++++++++++++++++++++++++++++     | 89% ~22s            |+++++++++++++++++++++++++++++++++++++++++++++     | 90% ~20s            |++++++++++++++++++++++++++++++++++++++++++++++    | 91% ~18s            |++++++++++++++++++++++++++++++++++++++++++++++    | 92% ~16s            |+++++++++++++++++++++++++++++++++++++++++++++++   | 93% ~14s            |+++++++++++++++++++++++++++++++++++++++++++++++   | 94% ~12s            |++++++++++++++++++++++++++++++++++++++++++++++++  | 95% ~10s            |++++++++++++++++++++++++++++++++++++++++++++++++  | 96% ~08s            |+++++++++++++++++++++++++++++++++++++++++++++++++ | 97% ~06s            |+++++++++++++++++++++++++++++++++++++++++++++++++ | 98% ~04s            |++++++++++++++++++++++++++++++++++++++++++++++++++| 99% ~02s            |++++++++++++++++++++++++++++++++++++++++++++++++++| 100% elapsed=03m 24s
:end:

#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
library(ggplot2)
library(data.table)
dt.res <- as.data.table(do.call(rbind,ls.res))
dt.res[, estimator := factor(estimator,
                             levels = c("cc","IPCWglm","IPCWcox","mets","oracle"),
                             labels = c("complete case","wrong IPCW (glm censoring model)","IPCW (riskRegression)","IPCW (mets)","oracle"))]
dt.res[, empirical.sd := sd(estimate), by  = c("n","tau","estimator")]
dt.res[, sample.size := factor(paste0("sample.size: ",n), levels = unique(paste0("sample.size: ",n)))]
gg.beta <- ggplot(dt.res, aes(y = estimate))
gg.beta <- gg.beta + geom_boxplot(aes(fill=estimator))
gg.beta <- gg.beta + facet_wrap(~sample.size)
gg.beta <- gg.beta + guides(fill = guide_legend(nrow = 3gggggggn, byrow = TRUE))
gg.beta <- gg.beta + theme(text = element_text(size=15),
                           axis.line = element_line(size = 1.25),
                           axis.ticks = element_line(size = 2),
                           axis.ticks.length=unit(.25, "cm"),
                           legend.position="bottom", 
                           legend.direction = "horizontal")

gg.beta
## ggsave(gg.beta, filename = "./figures/simStudy-bin-bias.pdf", width = 8.5)
#+END_SRC

#+RESULTS:
:results:
:end:

# #+BEGIN_SRC R :exports both :results output :session *R* :cache no
#   ##dt.res[estimator == "oracle", .(empirical = sd(estimate), model = mean(sd)),by="sample.size"]
#   res <- do.call(rbind,lapply(1:100, function(i){
#     dt <- simTrial(n = 1000,  dmu = c(0,1), dpC = c(0,1))
#     dt$responseUncensored <- dt$eventtimeUncensored<=tau
#     dt$response <- ifelse((dt$status==1)+(dt$eventtime>tau),dt$eventtime<=tau,NA)
#     dt$observed <- ifelse((dt$status==1)+(dt$eventtime>tau),1,0)
#     summary(glm(responseUncensored ~ treatment, data = dt, family = binomial(link="logit")))$coef[2,]
#   }))
# sd(res[,1])
# mean(res[,2])
# #+END_SRC

# #+RESULTS:
# : [1] 0.05509405
# : [1] 0.06338228

#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
gg.sd <- ggplot(dt.res, aes(y = sd))
gg.sd <- gg.sd + geom_boxplot(aes(fill=estimator, x = as.factor(n)))
gg.sd <- gg.sd + geom_point(aes(y=empirical.sd, x = as.factor(n)), shape = 2, size = 2) + geom_line(aes(y=empirical.sd, x = as.factor(n), group=estimator))
gg.sd <- gg.sd + facet_grid(~estimator) + xlab("sample size")
gg.sd <- gg.sd + theme(text = element_text(size=15),
                       axis.line = element_line(size = 1.25),
                       axis.ticks = element_line(size = 2),
                       axis.ticks.length=unit(.25, "cm"),
                       legend.position="bottom",
                       legend.direction = "horizontal")
gg.sd
#+END_SRC
#+RESULTS:
:results:
:end:

# * Reference
# # help: https://gking.harvard.edu/files/natnotes2.pdf

# #+BEGIN_EXPORT latex
# \begingroup
# \renewcommand{\section}[2]{}
# #+END_EXPORT
# bibliographystyle:apalike
# [[bibliography:bibliography.bib]] 
# #+BEGIN_EXPORT latex
# \endgroup
# #+END_EXPORT

#+BEGIN_EXPORT LaTeX
\appendix
\titleformat{\section}
{\normalfont\Large\bfseries}{}{1em}{Appendix~\thesection:~}

\renewcommand{\thefigure}{\Alph{figure}}
\renewcommand{\thetable}{\Alph{table}}
\renewcommand{\theequation}{\Alph{equation}}

\setcounter{figure}{0}    
\setcounter{table}{0}    
\setcounter{equation}{0}    
#+END_EXPORT

\clearpage

* Graphical display of the imputation (autoref:fig:imputationModel)
:PROPERTIES:
:CUSTOM_ID: SM:imputation
:END:

Alternative R code to fit a random intercept model
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(LMMstar)
e.lmm <- lmm(Yobs~time, repetition = ~time|id,
             structure = "CS", data = dtL.B)
eOracle.lmm <- lmm(Yobs~time*mdd, repetition = ~time|id,
                   structure = "CS", data = dtL.B)
#+END_SRC

#+RESULTS:

Identify patient with missing data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
id.NA <- unique(sort(dtL.B[is.na(Yobs),id]))
dtL.BNA <- dtL.B[id %in% id.NA==TRUE]
dtL.BNA$group2 <- paste0(dtL.BNA$mdd," (partially observed)")
dtL.BNNA <- dtL.B[id %in% id.NA==FALSE]
dtL.BNNA$group2 <- paste0(dtL.BNNA$mdd," (fully observed)")
#+END_SRC

#+RESULTS:

Identify patient with missing data and get the imputed value
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
pred.B <- predict(e.lmm, newdata = dtL.BNA, type = "dynamic",
                  keep.newdata = TRUE)
pred.B$mdd <- paste(pred.B$mdd," (imputed)")
predOracle.B <- predict(eOracle.lmm, newdata = dtL.BNA, type = "dynamic",
                        keep.newdata = TRUE)
predOracle.B$mdd <- paste(predOracle.B$mdd," (imputed)")
#+END_SRC

#+RESULTS:

Mixed model (feasible) estimate as a t-test on the imputed values:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
diff.lmm <- c(dtL.BNNA[,diff(Yobs),by="id"][[2]],
              pred.B[,estimate[2]-Yobs[1],by="id"][[2]])
t.test(diff.lmm)
coef(e.lmm)["timeT2"]
#+END_SRC

#+RESULTS:
#+begin_example

	One Sample t-test

data:  diff.lmm
t = -149.14, df = 1999, p-value < 2.2e-16
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 -35.17796 -34.26483
sample estimates:
mean of x 
-34.72139
   timeT2 
-34.72139
#+end_example

Mixed model (oracle) estimate as a t-test on the imputed values:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
diff.lmm.oracle <- c(dtL.BNNA[,diff(Yobs),by="id"][[2]],
                     predOracle.B[,estimate[2]-Yobs[1],by="id"][[2]])
t.test(diff.lmm.oracle)
glht(eOracle.lmm, linfct = "timeT2+0.5*timeT2:mddsevere=0")

#+END_SRC

#+RESULTS:
#+begin_example

	One Sample t-test

data:  diff.lmm.oracle
t = -125.01, df = 1999, p-value < 2.2e-16
alternative hypothesis: true mean is not equal to 0
95 percent confidence interval:
 -38.02137 -36.84682
sample estimates:
mean of x 
 -37.4341

	 General Linear Hypotheses

Linear Hypotheses:
                                     Estimate
timeT2 + 0.5 * timeT2:mddsevere == 0   -37.43
#+end_example

Graphical display (feasible):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gg.imp <- ggplot(mapping = aes(x=time, color = group2))
gg.imp <- gg.imp + geom_boxplot(data = dtL.BNNA, mapping = aes(y = Yobs))
gg.imp <- gg.imp + geom_boxplot(data = dtL.BNA, mapping = aes(y = Yobs))
gg.imp <- gg.imp + geom_boxplot(data = pred.B, mapping = aes(y = estimate))
gg.imp <- gg.imp + scale_color_manual("MDD group",
                                      values = c("limegreen","darkgreen","orange","red"))
gg.imp <- gg.imp + theme(text = element_text(size=15),
                         axis.line = element_line(size = 1.25),
                         axis.ticks = element_line(size = 2),
                         axis.ticks.length=unit(.25, "cm"),
                         legend.position="bottom",
                         legend.direction = "horizontal")
gg.imp
#+END_SRC

#+RESULTS:
: Advarselsbeskeder:
: 1: Removed 969 rows containing non-finite values (stat_boxplot). 
: 2: Removed 969 rows containing non-finite values (stat_boxplot).

Graphical display (oracle):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
gg.impOracle <- ggplot(mapping = aes(x=time, color = group2))
gg.impOracle <- gg.impOracle + geom_boxplot(data = dtL.BNNA, mapping = aes(y = Yobs))
gg.impOracle <- gg.impOracle + geom_boxplot(data = dtL.BNA, mapping = aes(y = Yobs))
gg.impOracle <- gg.impOracle + geom_boxplot(data = predOracle.B, mapping = aes(y = estimate))
gg.impOracle <- gg.impOracle + scale_color_manual("MDD group",
                                      values = c("limegreen","darkgreen","orange","red"))
gg.impOracle <- gg.impOracle + theme(text = element_text(size=15),
                         axis.line = element_line(size = 1.25),
                         axis.ticks = element_line(size = 2),
                         axis.ticks.length=unit(.25, "cm"),
                         legend.position="bottom",
                         legend.direction = "horizontal")
gg.impOracle
#+END_SRC

#+RESULTS:
: Advarselsbeskeder:
: 1: Removed 969 rows containing non-finite values (stat_boxplot). 
: 2: Removed 969 rows containing non-finite values (stat_boxplot).

#+ATTR_LATEX: :options otherkeywords={}, deletekeywords={}
#+BEGIN_SRC R :exports none :results output raw drawer :session *R* :cache no
library(ggpubr)
ggsave(ggpubr::ggarrange(gg.imp + ggtitle("Misspecified outcome model (~time)"), gg.impOracle + ggtitle("valid outcome model (~time*mdd)"),
                         common.legend = TRUE, legend = "bottom"),
       filename = "figures/gg-imputationModel.pdf", width = 12)
#+END_SRC

#+RESULTS:
:results:
Saving 12 x 6.38 in image
Advarselsbeskeder:
1: Removed 969 rows containing non-finite values (stat_boxplot). 
2: Removed 969 rows containing non-finite values (stat_boxplot). 
3: Removed 969 rows containing non-finite values (stat_boxplot). 
4: Removed 969 rows containing non-finite values (stat_boxplot). 
5: Removed 969 rows containing non-finite values (stat_boxplot). 
6: Removed 969 rows containing non-finite values (stat_boxplot).
:end:

* CONFIG :noexport:
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t

** Display of the document
# ## space between lines
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}

# ## margins
#+LATEX_HEADER:\geometry{top=1cm}

# ## personalize the prefix in the name of the sections
#+LaTeX_HEADER: \usepackage{titlesec}
# ## fix bug in titlesec version
# ##  https://tex.stackexchange.com/questions/299969/titlesec-loss-of-section-numbering-with-the-new-update-2016-03-15
#+LaTeX_HEADER: \usepackage{etoolbox}
#+LaTeX_HEADER: 
#+LaTeX_HEADER: \makeatletter
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\noindent}{}{}{}
#+LaTeX_HEADER: \makeatother

** Color
# ## define new colors
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LaTeX_HEADER: \definecolor{myorange}{rgb}{1,0.2,0}
#+LaTeX_HEADER: \definecolor{mypurple}{rgb}{0.7,0,8}
#+LaTeX_HEADER: \definecolor{mycyan}{rgb}{0,0.6,0.6}
#+LaTeX_HEADER: \newcommand{\lightblue}{blue!50!white}
#+LaTeX_HEADER: \newcommand{\darkblue}{blue!80!black}
#+LaTeX_HEADER: \newcommand{\darkgreen}{green!50!black}
#+LaTeX_HEADER: \newcommand{\darkred}{red!50!black}
#+LaTeX_HEADER: \definecolor{gray}{gray}{0.5}

# ## change the color of the links
#+LaTeX_HEADER: \hypersetup{
#+LaTeX_HEADER:  citecolor=[rgb]{0,0.5,0},
#+LaTeX_HEADER:  urlcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER:  linkcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER: }

** Font
# https://tex.stackexchange.com/questions/25249/how-do-i-use-a-particular-font-for-a-small-section-of-text-in-my-document
#+LaTeX_HEADER: \newenvironment{note}{\small \color{gray}\fontfamily{lmtt}\selectfont}{\par}
#+LaTeX_HEADER: \newenvironment{activity}{\color{orange}\fontfamily{qzc}\selectfont}{\par}

** Symbols
# ## valid and cross symbols
#+LaTeX_HEADER: \RequirePackage{pifont}
#+LaTeX_HEADER: \RequirePackage{relsize}
#+LaTeX_HEADER: \newcommand{\Cross}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{56}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\Valid}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{52}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\CrossR}{ \textcolor{red}{\Cross} }
#+LaTeX_HEADER: \newcommand{\ValidV}{ \textcolor{green}{\Valid} }

# ## warning symbol
#+LaTeX_HEADER: \usepackage{stackengine}
#+LaTeX_HEADER: \usepackage{scalerel}
#+LaTeX_HEADER: \newcommand\Warning[1][3ex]{%
#+LaTeX_HEADER:   \renewcommand\stacktype{L}%
#+LaTeX_HEADER:   \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
#+LaTeX_HEADER:   \xspace
#+LaTeX_HEADER: }

# # R Software
#+LATEX_HEADER: \newcommand\Rlogo{\textbf{\textsf{R}}\xspace} % 

** Code
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*

# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}

# ## change font size input (global change)
# ## doc: https://ctan.math.illinois.edu/macros/latex/contrib/listings/listings.pdf
# #+LATEX_HEADER: \newskip\skipamount   \skipamount =6pt plus 0pt minus 6pt
# #+LATEX_HEADER: \lstdefinestyle{code-tiny}{basicstyle=\ttfamily\tiny, aboveskip =  kipamount, belowskip =  kipamount}
# #+LATEX_HEADER: \lstset{style=code-tiny}
# ## change font size input (local change, put just before BEGIN_SRC)
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output (global change)
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}

** Lists
#+LATEX_HEADER: \RequirePackage{enumitem} % better than enumerate

** Image and graphs
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics

#+LaTeX_HEADER: \RequirePackage{tikz-cd} % graph
# ## https://tools.ietf.org/doc/texlive-doc/latex/tikz-cd/tikz-cd-doc.pdf

** Table
#+LATEX_HEADER: \RequirePackage{booktabs} % for nice lines in table (e.g. toprule, bottomrule, midrule, cmidrule)

** Inline latex
# @@latex:any arbitrary LaTeX code@@


** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}

** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)

# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}

*** Template for shortcut
#+LATEX_HEADER: \usepackage{ifthen}
#+LATEX_HEADER: \usepackage{xifthen}
#+LATEX_HEADER: \usepackage{xargs}
#+LATEX_HEADER: \usepackage{xspace}

#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }

**** Probability
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}

#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}

#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\logLikelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}

**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}

#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}

#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}

#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\partial #2^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 

**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}

#+LATEX_HEADER: \newcommand\Veta{\boldsymbol{\eta}}
#+LATEX_HEADER: \newcommand\VX{\mathbf{X}}
#+LATEX_HEADER: \newcommand\sample{\chi}
#+LATEX_HEADER: \newcommand\Hspace{\mathcal{H}}
#+LATEX_HEADER: \newcommand\Tspace{\mathcal{T}}


** Notations
