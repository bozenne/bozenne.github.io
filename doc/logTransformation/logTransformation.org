#+TITLE: Estimating a relative change using a log-transformation of the outcome
#+Author: Brice Ozenne

* Interpretation of the regression coefficient after log-transformation
Let's denote by \(Y\) the outcome and by \(G\) a binary group
variable. We are interested in the relative change in \(Y\) between
the groups. We decide to model the group effect on the log scale:
#+BEGIN_EXPORT latex
\begin{align*}
\log(Y) = Z = \alpha + \beta G + \varepsilon \text{ where } \Esp[\varepsilon]=0 \text{ and } \Esp[\varepsilon]=\sigma^2
\end{align*}
#+END_EXPORT
We claim that:
#+BEGIN_EXPORT latex
\begin{align*}
\frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]} = e^{\beta} - 1
\end{align*}
#+END_EXPORT

** Proof: re-writting the model as a multiplicative model
We can re-write the model as:
#+BEGIN_EXPORT latex
\begin{align*}
Y = e^{\alpha + \beta G}e^{\varepsilon} \text{ where }
\end{align*}
#+END_EXPORT
So for \(g\in\{1,2\}\):
#+BEGIN_EXPORT latex
\begin{align*}
\Esp[Y|G=g] = e^{\alpha + \beta g} \Esp[e^{\varepsilon}]
\end{align*}
#+END_EXPORT
Then:
#+BEGIN_EXPORT latex
\begin{align*}
\frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]}
& = \frac{e^{\alpha + \beta} \Esp[e^{\varepsilon}]-e^{\alpha} \Esp[e^{\varepsilon}]}{e^{\alpha} \Esp[e^{\varepsilon}]} \\
& = \frac{e^{\alpha + \beta} -e^{\alpha}}{e^{\alpha}}  = e^{\beta} - 1 \\
\end{align*}
#+END_EXPORT

** Proof: using a Taylor expansion

Using a second order Taylor expansion of \(\exp(Z)\) around
\(\mu(G)=\alpha + \beta G\) and assuming that the first moments of
\(Z\) are finite and the remaining moments are neglectable regarding
the factorial of the moment order (i.e. \(\forall i \geq 1 \),
\(\frac{1}{i!}\Esp[\varepsilon^i ]< +\infty\) and \(\sum_{i=1}^{\infty} \frac{1}{i!}\Esp[\varepsilon^i ]< +\infty\)), we get:
#+BEGIN_EXPORT latex
\begin{align*}
Y &= e^{Z} = e^{\mu} + \sum_{i=1}^{\infty} \frac{1}{i!} (Z - \mu)^i \frac{\partial^i e^{\mu}}{(\partial \mu)^i} \\
&= e^{\alpha + \beta G} + \sum_{i=1}^{\infty} \frac{1}{i!} (Z - \alpha - \beta G)^i e^{\alpha + \beta G} \\
\Esp[Y|G=g] &= e^{\alpha + \beta G} + \sum_{i=1}^{\infty} \frac{1}{i!} \Esp[(Z - \alpha - \beta g)^i] e^{\alpha + \beta G} \\
&= e^{\alpha + \beta G} \left(1 + \sum_{i=1}^{\infty} \frac{1}{i!} \Esp[\varepsilon^i] \right)
\end{align*}
#+END_EXPORT
where we used that the distribution of \(\varepsilon\) is independent
of \(g\). We can now express our parameter of interest:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta_G &= \frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]} = \frac{\Esp[Y|G=1]}{\Esp[Y|G=0]} - 1 \\
&= \frac{e^{\alpha + \beta} \left(1 + \sum_{i=1}^{\infty} \frac{1}{i!} \Esp[\varepsilon^{i}] \right)}{e^{\alpha} \left(1 + \sum_{i=1}^{\infty} \frac{1}{i!} \Esp[\varepsilon^{i}] \right)} - 1 \\
&= e^{\beta} - 1
\end{align*}
#+END_EXPORT


# @@latex:any arbitrary LaTeX code@@
\clearpage

* Example :noexport:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(lava)
m <- lvm(Y[5] ~ G)
categorical(m, K=2) <- ~G
transform(m, Z~Y) <- function(z){log(z)}

d <- lava::sim(m, n = 1e5)
head(d)
#+END_SRC

#+RESULTS:
:          Y G        Z
: 1 4.941076 1 1.597583
: 2 4.184619 0 1.431416
: 3 4.757324 0 1.559685
: 4 5.596557 1 1.722152
: 5 5.368230 0 1.680498
: 6 5.668698 0 1.734960

Fit models:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
coef.id <- coef(lm(Y ~ G, data = d))
coef.log <- coef(lm(Z ~ G, data = d))

list(id = coef.id,
     log = coef.log)
#+END_SRC

#+RESULTS:
: $id
: (Intercept)           G 
:   5.0035836   0.9923204 
: 
: $log
: (Intercept)           G 
:   1.5888092   0.1879317

Relative change estimated by several methods:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
c(id = as.double(coef.id["G"]/coef.id["(Intercept)"]), 
  log = as.double(exp(coef.log["G"])-1), 
  GS = as.double(mean(d[d$G==1,"Y"])/mean(d[d$G==0,"Y"]) - 1),
  true = 1/5)
#+END_SRC

#+RESULTS:
:        id       log        GS      true 
: 0.1983219 0.2067510 0.1983219 0.2000000

Performance in small samples:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
warper <- function(m, n){
    d <- lava::sim(m, n = n)
    coef.id <- coef(lm(Y ~ G, data = d))
    coef.log <- coef(lm(Z ~ G, data = d))
    out <- c(id = as.double(coef.id["G"]/coef.id["(Intercept)"]), 
             log = as.double(exp(coef.log["G"])-1))
    return(out)
}
M.res <- do.call(rbind,lapply(1:1000, function(i){warper(m, n = 12)}))
#+END_SRC

#+RESULTS:

Bias:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
colMeans(M.res-1/5)
#+END_SRC

#+RESULTS:
:         id        log 
: 0.01062298 0.01824621

Variance:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
apply(M.res,2,var)
#+END_SRC

#+RESULTS:
:         id        log 
: 0.01973720 0.02136166

Root mean squared error:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
colMeans((M.res-1/5)^2)
#+END_SRC

#+RESULTS:
:  change.id change.log 
: 0.01946796 0.02202432

In this simulation, the change computed with the log model has a
slightly larger bias and variance, with a quite similar root mean
squared error are quite similar. Here the true model was the additive
one (i.e. no tranformation) but we see that the multiplicative
one(i.e. log-transformation) gives valid results (even though the
distribution of the residuals is not normal on the log-scale). So the
model choice should be made on which of the two models: additive or
multiplicative is more likely to be correctly specified.

\clearpage

* Note for power calculation

** Recall: delta-method for normally distributed variables

\textbf{Theory}: we recall that for a random variable \(Y\) with finite first two
moments, the delta method applied around the mean for a transformation
\(f\) is:
#+BEGIN_EXPORT latex
\begin{align*}
f(Y) = f(\mu) + f'(\mu) (Y-\mu) + \frac{1}{2} f''(\mu) (Y-\mu)^2  + \frac{1}{6} f'''(\mu) (Y-\mu)^3 + o\left((Y-\mu)^2\right)
\end{align*}
#+END_EXPORT
where \(\mu=\Esp[Y]\). Introducing \(\sigma^2 = \Var[Y]\), we have:
#+BEGIN_EXPORT latex
\begin{align*}
\Esp[f(Y)] =& f(\mu) + f'(\mu) (\Esp[Y]-\mu) + \frac{1}{2} f''(\mu) \Esp[(Y-\mu)^2] + \frac{1}{6} f'''(\mu) \Esp[(Y-\mu)^3] + o\left(\Esp[(Y-\mu)^3]\right) \\
=& f(\mu) + \frac{\sigma^2}{2} f''(\mu)  + o\left(\Esp[(Y-\mu)^3]\right)
\end{align*}
#+END_EXPORT
for a normal distribution since \(\Esp[(Y-\mu)^3]=0\). Also:
#+BEGIN_EXPORT latex
\begin{align*}
\Var[f(Y)] =& \left(f'(\mu)\right)^2 \Var\left[\Esp[Y]-\mu\right] + f'(\mu)f''(\mu) \Esp[(Y-\mu)^3] \\
& +\left(\frac{f'(\mu) f'''(\mu)}{3} + \frac{\left(f''(\mu)\right)^2}{4}\right) \Esp[(Y-\mu)^4] + o\left(\Esp[(Y-\mu)^4]\right) \\
=& \left(f'(\mu)\right)^2 \sigma^2 + 3 \sigma^4 \left(\frac{f'(\mu) f'''(\mu)}{3} + \frac{\left(f''(\mu)\right)^2}{4}\right) + o\left(\Esp[(Y-\mu)^4]\right) \\
\end{align*}
#+END_EXPORT

\bigskip

\textbf{Application}:  exponential transformation (\(f = \exp\))
#+BEGIN_EXPORT latex
\begin{align*}
\Esp[\exp(Y)] &\approx \exp(\mu)\left(1 + \frac{\sigma^2}{2}\right) \\
\Var[\exp(Y)] &\approx \exp(2\mu)\left(\sigma^2 + \frac{7}{4} \sigma^4\right) \\
\end{align*}
#+END_EXPORT

\clearpage

\textbf{Illustration}: We consider a normally distributed outcome with
expectation 0.1 and variance 0.1. What is its expectation and variance
after log-transformation?
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10); n <- 1e4
mu <- 0.1; sigma2 <- 0.1

## first order method
mu.exp1 <- exp(mu)
var.exp1 <- exp(2*mu)*sigma2

## second order method
mu.exp2 <- exp(mu)*(1+sigma2/2)
var.exp2 <- exp(2*mu)*(sigma2 + (7/4)*sigma2^2)

## empirical value
X.exp <- exp(rnorm(n, mean = mu, sd = sqrt(sigma2)))
mu.expGS <- mean(X.exp)
var.expGS <-  var(X.exp)
#+END_SRC

#+RESULTS:

Comparison mean:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
rbind(value = c(first.order = mu.exp1, 
                second.order = mu.exp2, 
                truth = mu.expGS),
      bias = c(mu.exp1,mu.exp2,mu.expGS)-mu.expGS,
      relative.bias = (c(mu.exp1,mu.exp2,mu.expGS)-mu.expGS)/mu.expGS)
#+END_SRC

#+RESULTS:
:               first.order second.order    truth
: value          1.10517092  1.160429464 1.163026
: bias          -0.05785477 -0.002596223 0.000000
: relative.bias -0.04974505 -0.002232301 0.000000

Comparison variance:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
rbind(value = c(first.order = var.exp1, 
                second.order = var.exp2, 
                truth = var.expGS),
      bias = c(var.exp1,var.exp2,var.expGS)-var.expGS,
      relative.bias = (c(var.exp1,var.exp2,var.expGS)-var.expGS)/var.expGS)
#+END_SRC

#+RESULTS:
:               first.order  second.order     truth
: value          0.12214028  0.1435148241 0.1444692
: bias          -0.02232895 -0.0009544035 0.0000000
: relative.bias -0.15455853 -0.0066062752 0.0000000

The second order estimate is much more accurate, especially for the
variance.

** Two independent groups - normal distribution

\textbf{Theory}: consider two groups \(G=0\) and \(G=1\) for which we
want to compare the percentage difference in outcome \(Y\). We are
willing to assume that on the log-scale \(Y\) is normally
distributed. Our parameter of interest is:
#+BEGIN_EXPORT latex
\begin{align*}
\frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]} = \gamma
\end{align*}
#+END_EXPORT
we denote \(\alpha = \Esp[Y|G=0]\) and we assume that on the original scale:
#+BEGIN_EXPORT latex
\begin{align*}
\Var[Y|G=1]  = \Var[Y|G=0] = \sigma^2
\end{align*}
#+END_EXPORT
How should be parametrized the gaussian distribution of
\(\log(Y)|G=0\) and \(\log(Y)|G=1\) to satisfy
\((\alpha,\gamma,\sigma^2)\)? In other words we want to find
\(m_0,m_1,s_0,s_1\) such that:
#+BEGIN_EXPORT latex
\begin{align*}
Z_0 = \log(Y)|G=0 &\sim \Gaus\left(m_0,s^2_0\right) \\
Z_1 = \log(Y)|G=1 &\sim \Gaus\left(m_1,s^2_1\right) 
\end{align*}
#+END_EXPORT
We can use the delta method to identify these parameters since:
#+BEGIN_EXPORT latex
\begin{align*}
\alpha &= \Esp[\exp(Z_0)] = \exp(a_0)\left(1 + \frac{s^2_0}{2}\right) \\
\sigma^2 &= \Var[\exp(Z_0)] = \exp(2 a_0)\left(s^2_0 + \frac{7}{4}s^4_0\right) \\
\alpha (\gamma + 1) &= \Esp[\exp(Z_1)] = \exp(a_1)\left(1 + \frac{s^2_1}{2}\right)\\
\sigma^2 &= \Var[\exp(Z_1)] = \exp(2 a_1)\left(s^2_1 + \frac{7}{4}s^4_1\right)
\end{align*}
#+END_EXPORT
i.e.
#+BEGIN_EXPORT latex
\begin{align*}
\frac{\alpha^2}{\sigma^2} = \frac{\left(1+\frac{s_0^2}{2}\right)^2}{s^2_0 + \frac{7}{4}s^4_0}            \qquad &\rightarrow \text{gives } s_0 \\
a_0 = \frac{1}{2}\log\left(\frac{\sigma^2}{\left(s^2_0 + \frac{7}{4}s^4_0\right)}\right)                \qquad &\rightarrow \text{gives } a_0 \\
\frac{\alpha^2(\gamma+1)^2}{\sigma^2} = \frac{\left(1+\frac{s_1^2}{2}\right)^2}{s^2_1 + \frac{7}{4}s^4_1}\qquad &\rightarrow \text{gives } s_1 \\
a_1 = \frac{1}{2}\log\left(\frac{\sigma^2}{\left(s^2_1 + \frac{7}{4}s^4_1\right)}\right)                \qquad &\rightarrow \text{gives } a_1 
\end{align*}
#+END_EXPORT 
The first and third equation can be solved numerically.

\clearpage

\textbf{Illustration}: We consider two groups having a 10% difference
in their baseline value (\(\alpha=1.15\)) and a variance of \(\sigma^2
= 0.15\). What are the parameters of the corresponding normal
distribution on the log-scale and the standardized effect size?
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alpha <- 1.15
sigma2 <- 0.15
gamma <- 0.1
#+END_SRC

#+RESULTS:

Solve the equations:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
s0 <- uniroot(function(x){alpha^2/sigma2 - (1+x/2)^2/(x+x^2*7/4)},
              interval = c(0,1))$root
a0 <- log(sigma2/(s0+s0^2*7/4))/2
s1 <- uniroot(function(x){alpha^2*(gamma+1)^2/sigma2 - (1+x/2)^2/(x+x^2*7/4)},
              interval = c(0,1))$root
a1 <- log(sigma2/(s1+s1^2*7/4))/2
c(a0 = a0, s0 = s0, a1 = a1, s1 = s1)
#+END_SRC

#+RESULTS:
:         a0         s0         a1         s1 
: 0.08802784 0.10608948 0.19175319 0.08851048

We can check that =uniroot= converged correctly:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
c(exp(a0)*(1+s0/2) - alpha, 
  exp(2*a0)*(s0+s0^2*7/4) - sigma2, 
  exp(a1)*(1+s1/2) - alpha*(1+gamma), 
  exp(2*a1)*(s1+s1^2*7/4) - sigma2)
#+END_SRC

#+RESULTS:
: [1] -5.563198e-05  0.000000e+00 -1.895835e-05  0.000000e+00

and the variables have the appropriate distribution:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
Z0 <- exp(rnorm(1e4, mean=a0, sd = sqrt(s0)))
Z1 <- exp(rnorm(1e4, mean=a1, sd = sqrt(s1)))
c(alpha = mean(Z0), 
  gamma = (mean(Z1)-mean(Z0))/mean(Z0), 
  sigma2 = var(Z0), 
  sigma2 = var(Z1))
#+END_SRC

#+RESULTS:
:     alpha     gamma    sigma2    sigma2 
: 1.1435272 0.1090391 0.1473705 0.1507638

For a power calculation we would use:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
pwr.t.test(d = (a1-a0)/sqrt(s0/2+s1/2), sig.level = 0.05, power = 0.8)
## dvmisc::power_2t_unequal(n = 143, d = a1-a0, sigsq1 = s0, sigsq2 = s1, alpha = 0.05)
#+END_SRC

#+RESULTS:
#+begin_example

     Two-sample t test power calculation 

              n = 142.9312
              d = 0.3325282
      sig.level = 0.05
          power = 0.8
    alternative = two.sided

NOTE: n is number in *each* group
#+end_example

# Check:
# #+BEGIN_SRC R :exports both :results output :session *R* :cache no
# out <- sapply(1:10000,function(x){t.test(rnorm(143, mean = alpha, sd = sqrt(sigma2)),rnorm(143, mean = alpha*(1+gamma), sd = sqrt(sigma2)))$p.value})
# mean(out<=0.05)
# #+END_SRC

# #+RESULTS:
# : [1] 0.7084

# #+BEGIN_SRC R :exports both :results output :session *R* :cache no
# out <- sapply(1:10000,function(x){t.test(rnorm(143, mean = a0, sd = sqrt(s0)),rnorm(143, mean = a1, sd = sqrt(s1)))$p.value})
# mean(out<=0.05)
# #+END_SRC

# #+RESULTS:
# : [1] 0.8003

** Two independent groups - log-normal distribution

An alternative approach is to use a log-normal distribution. Random
variables with log normal distribution have their logarithm equal to a
specific value \(a\) and their standard deviation equal to a specific
value \(s\). So we want to get:
#+BEGIN_EXPORT latex
\begin{align*}
\alpha &= \exp(a_0 + \frac{1}{2} s_0^2) \\
\sigma^2 &= \exp(2*a_0 + s_0^2)*(\exp(s_0^2)-1) \\
\alpha (1+\gamma) &= \exp(a_1 + \frac{1}{2} s_1^2) \\
\sigma^2 &= \exp(2*a_1 + s_1^2)*(\exp(s_1^2)-1)
\end{align*}
#+END_EXPORT
So
#+BEGIN_EXPORT latex
\begin{align*}
s_0 &= \log\left(1+\frac{\sigma^2}{\alpha^2}\right)\\
a_0 &= \log(\alpha)-\frac{s_0^2}{2}\\
s_1 &= \log\left(1+\frac{\sigma^2}{\alpha*(1+\gamma)^2}\right)\\
a_1 &= \log(\alpha*(1+\gamma))-\frac{s_1^2}{2}
\end{align*}
#+END_EXPORT

\clearpage

\textbf{Illustration}: We still consider two groups having a 10%
difference in their baseline value (\(\alpha=1.15\)) and a variance of
\(\sigma^2 = 0.15\). What are the parameters of the corresponding
normal distribution on the log-scale and the standardized effect size?
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alpha <- 1.15
sigma2 <- 0.15
gamma <- 0.1
#+END_SRC

#+RESULTS:

We identify the parameters of the log-normal distributions:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
s0 <- log(1+sigma2/alpha^2)
a0 <- log(alpha) - s0/2 
s1 <- log(1+sigma2/(alpha*(1+gamma))^2)
a1 <- log(alpha*(1+gamma)) - s1/2 
c(a0 = a0, s0 = s0, a1 = a1, s1 = s1)
#+END_SRC

#+RESULTS:
:         a0         s0         a1         s1 
: 0.08604307 0.10743775 0.19027207 0.08960011

We can check that the variables have the appropriate distribution:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
Z0 <- rlnorm(1e4, mean=a0, sd = sqrt(s0))
Z1 <- rlnorm(1e4, mean=a1, sd = sqrt(s1))
c(alpha = mean(Z0), 
  gamma = (mean(Z1)-mean(Z0))/mean(Z0), 
  sigma2 = var(Z0), 
  sigma2 = var(Z1))
#+END_SRC

#+RESULTS:
:     alpha     gamma    sigma2    sigma2 
: 1.1480725 0.1019535 0.1455856 0.1510286

For a power calculation we would use:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
pwr.t.test(d = (a1-a0)/sqrt(s0/2+s1/2), sig.level = 0.05, power = 0.8)
## dvmisc::power_2t_unequal(n = 143, d = a1-a0, sigsq1 = s0, sigsq2 = s1, alpha = 0.05)
#+END_SRC

#+RESULTS:
#+begin_example

     Two-sample t test power calculation 

              n = 143.3238
              d = 0.3320693
      sig.level = 0.05
          power = 0.8
    alternative = two.sided

NOTE: n is number in *each* group
#+end_example

* CONFIG :noexport:
# #+LaTeX_HEADER:\affil{Department of Biostatistics, University of Copenhagen, Copenhagen, Denmark}
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t

** Latex command
#+LATEX_HEADER: \RequirePackage{ifthen}
#+LATEX_HEADER: \RequirePackage{xifthen}
#+LATEX_HEADER: \RequirePackage{xargs}
#+LATEX_HEADER: \RequirePackage{xspace}

#+LATEX_HEADER: \newcommand\Rlogo{\textbf{\textsf{R}}\xspace} % 

** Notations

** Code
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*

# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}

# ## change font size input
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}

** Display 
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\usepackage{authblk} % enable several affiliations (clash with beamer)
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}
#+LATEX_HEADER:\geometry{top=1cm}

** Image
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics


** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}

** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)

# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}

*** Template for shortcut
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }

*** Shortcuts

**** Probability
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}

#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}

#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}

**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}

#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}

#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}

#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\left( \partial #2\right)^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 

**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
