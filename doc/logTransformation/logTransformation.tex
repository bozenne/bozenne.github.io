% Created 2020-06-15 ma 17:16
% Intended LaTeX compiler: pdflatex
\documentclass[12pt]{article}

%%%% settings when exporting code %%%% 

\usepackage{listings}
\lstset{
backgroundcolor=\color{white},
basewidth={0.5em,0.4em},
basicstyle=\ttfamily\small,
breakatwhitespace=false,
breaklines=true,
columns=fullflexible,
commentstyle=\color[rgb]{0.5,0,0.5},
frame=single,
keepspaces=true,
keywordstyle=\color{black},
literate={~}{$\sim$}{1},
numbers=left,
numbersep=10pt,
numberstyle=\ttfamily\tiny\color{gray},
showspaces=false,
showstringspaces=false,
stepnumber=1,
stringstyle=\color[rgb]{0,.5,0},
tabsize=4,
xleftmargin=.23in,
emph={anova,apply,class,coef,colnames,colNames,colSums,dim,dcast,for,ggplot,head,if,ifelse,is.na,lapply,list.files,library,logLik,melt,plot,require,rowSums,sapply,setcolorder,setkey,str,summary,tapply},
emphstyle=\color{blue}
}

%%%% packages %%%%%

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp}
\usepackage{color}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{changes}
\usepackage{pdflscape}
\usepackage{geometry}
\usepackage[normalem]{ulem}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{array}
\usepackage{ifthen}
\usepackage{hyperref}
\usepackage{natbib}
\RequirePackage{ifthen}
\RequirePackage{xifthen}
\RequirePackage{xargs}
\RequirePackage{xspace}
\newcommand\Rlogo{\textbf{\textsf{R}}\xspace} %
\RequirePackage{fancyvrb}
\DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
\RequirePackage{colortbl} % arrayrulecolor to mix colors
\RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
\usepackage{authblk} % enable several affiliations (clash with beamer)
\renewcommand{\baselinestretch}{1.1}
\geometry{top=1cm}
\RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
\RequirePackage{capt-of} %
\RequirePackage{caption} % newlines in graphics
\RequirePackage{amsmath}
\RequirePackage{algorithm}
\RequirePackage[noend]{algpseudocode}
\RequirePackage{dsfont}
\RequirePackage{amsmath,stmaryrd,graphicx}
\RequirePackage{prodint} % product integral symbol (\PRODI)
\newcommand\defOperator[7]{%
\ifthenelse{\isempty{#2}}{
\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
}{
\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
}
}
\newcommand\defUOperator[5]{%
\ifthenelse{\isempty{#1}}{
#5\left#3 #2 \right#4
}{
\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
}
}
\newcommand{\defBoldVar}[2]{
\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
}
\newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
\newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
\newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
\newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
\newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
\newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
\newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
\newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
\newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
\newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
\newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
\newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
\newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
\newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
\newcommandx\Hypothesis[2][1=,2=]{
\ifthenelse{\isempty{#1}}{
\mathcal{H}
}{
\ifthenelse{\isempty{#2}}{
\mathcal{H}_{#1}
}{
\mathcal{H}^{(#2)}_{#1}
}
}
}
\newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
\ifthenelse{\isempty{#3}}{
\frac{#4 #1}{#4 #2}
}{
\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
}
}
\newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
\newcommandx\ddpartial[3][1=,2=,3=]{
\ifthenelse{\isempty{#3}}{
\frac{\partial^{2} #1}{\left( \partial #2\right)^2}
}{
\frac{\partial^2 #1}{\partial #2\partial #3}
}
}
\newcommand\Real{\mathbb{R}}
\newcommand\Rational{\mathbb{Q}}
\newcommand\Natural{\mathbb{N}}
\newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
\newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
\newcommand\half{\frac{1}{2}}
\newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
\newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
\author{Brice Ozenne}
\date{\today}
\title{Estimating a relative change using a log-transformation of the outcome}
\hypersetup{
 colorlinks=true,
 citecolor=[rgb]{0,0.5,0},
 urlcolor=[rgb]{0,0,0.5},
 linkcolor=[rgb]{0,0,0.5},
 pdfauthor={Brice Ozenne},
 pdftitle={Estimating a relative change using a log-transformation of the outcome},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 25.2.1 (Org mode 9.0.4)},
 pdflang={English}
 }
\begin{document}

\maketitle

\section{Result}
\label{sec:org6b8bc61}
Let's denote by \(Y\) the outcome and by \(G\) a group variable
\(G\) (binary variable). We are interested in the relative change in \(Y\) between the
groups. We decide to model the group effect on the log scale:
\begin{align*}
\log(Y) = Z = \alpha + \beta G + \varepsilon \text{ where } \varepsilon \sim \Gaus[0,\sigma^2]
\end{align*}
We claim that:
\begin{align*}
\frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]} = e^{\beta} - 1
\end{align*}

\section{Proof}
\label{sec:org8caff4f}

\subsection{Re-writting the model as a multiplicative model}
\label{sec:orgb244dee}
We can re-write the model as:
\begin{align*}
Y = e^{\alpha + \beta G}e^{\varepsilon} \text{ where } \varepsilon \sim \Gaus[0,\sigma^2]
\end{align*}
So for \(g\in\{1,2\}\):
\begin{align*}
\Esp[Y|G=g] = e^{\alpha + \beta g} \Esp[e^{\varepsilon}]
\end{align*}
Then:
\begin{align*}
\frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]}
& = \frac{e^{\alpha + \beta} \Esp[e^{\varepsilon}]-e^{\alpha} \Esp[e^{\varepsilon}]}{e^{\alpha} \Esp[e^{\varepsilon}]} \\
& = \frac{e^{\alpha + \beta} -e^{\alpha}}{e^{\alpha}}  = e^{\beta} - 1 \\
\end{align*}

\subsection{Using a Taylor expansion}
\label{sec:org59193d1}


Using a second order Taylor expansion of \(\exp(Z)\) around
\(\mu(G)=\alpha + \beta G\) and assuming that the first moments of
\(Z\) are finite and the remaining moments are neglectable regarding
the factorial of the moment order (i.e. \(\forall i \geq 1\),
\(\frac{1}{i!}\Esp[\varepsilon^i ]< +\infty\) and \(\sum_{i=1}^{\infty} \frac{1}{i!}\Esp[\varepsilon^i ]< +\infty\)), we get:
\begin{align*}
Y &= e^{Z} = e^{\mu} + \sum_{i=1}^{\infty} \frac{1}{i!} (Z - \mu)^i \frac{\partial^i e^{\mu}}{(\partial \mu)^i} \\
&= e^{\alpha + \beta G} + \sum_{i=1}^{\infty} \frac{1}{i!} (Z - \alpha - \beta G)^i e^{\alpha + \beta G} \\
\Esp[Y|G=g] &= e^{\alpha + \beta G} + \sum_{i=1}^{\infty} \frac{1}{i!} \Esp[(Z - \alpha - \beta g)^i] e^{\alpha + \beta G} \\
&= e^{\alpha + \beta G} \left(1 + \sum_{i=1}^{\infty} \frac{1}{i!} \Esp[\varepsilon^i] \right)
\end{align*}
where we used that the distribution of \(\varepsilon\) is independent
of \(g\). [Optional] \(\varepsilon\) follows a zero-mean normal distribution, so
the uneven moments are 0:
\begin{align*}
\Esp[Y|G=g] &= e^{\alpha + \beta G} \left(1 + \sum_{i=1}^{\infty} \frac{1}{2i!} \Esp[\varepsilon^{2i}] \right)
\end{align*}
We can now express our parameter of interest:
\begin{align*}
\Delta_G &= \frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]} = \frac{\Esp[Y|G=1]}{\Esp[Y|G=0]} - 1 \\
&= \frac{e^{\alpha + \beta} \left(1 + \sum_{i=1}^{\infty} \frac{1}{2i!} \Esp[\varepsilon^{2i}] \right)}{e^{\alpha} \left(1 + \sum_{i=1}^{\infty} \frac{1}{2i!} \Esp[\varepsilon^{2i}] \right)} - 1 \\
&= e^{\beta} - 1
\end{align*}


\clearpage

\section{Note for power calculation}
\label{sec:orgd6c9c5c}

\subsection{Recall: delta-method for normally distributed variables}
\label{sec:org2be0bf6}

\textbf{Theory}: we recall that for a random variable \(Y\) with finite first two
moments, the delta method applied around the mean for a transformation
\(f\) is:
\begin{align*}
f(Y) = f(\mu) + f'(\mu) (Y-\mu) + \frac{1}{2} f''(\mu) (Y-\mu)^2  + \frac{1}{6} f'''(\mu) (Y-\mu)^3 + o\left((Y-\mu)^2\right)
\end{align*}
where \(\mu=\Esp[Y]\). Introducing \(\sigma^2 = \Var[Y]\), we have:
\begin{align*}
\Esp[f(Y)] =& f(\mu) + f'(\mu) (\Esp[Y]-\mu) + \frac{1}{2} f''(\mu) \Esp[(Y-\mu)^2] + \frac{1}{6} f'''(\mu) \Esp[(Y-\mu)^3] + o\left(\Esp[(Y-\mu)^3]\right) \\
=& f(\mu) + \frac{\sigma^2}{2} f''(\mu)  + o\left(\Esp[(Y-\mu)^3]\right)
\end{align*}
for a normal distribution since \(\Esp[(Y-\mu)^3]=0\). Also:
\begin{align*}
\Var[f(Y)] =& \left(f'(\mu)\right)^2 \Var\left[\Esp[Y]-\mu\right] + f'(\mu)f''(\mu) \Esp[(Y-\mu)^3] \\
& +\left(\frac{f'(\mu) f'''(\mu)}{3} + \frac{\left(f''(\mu)\right)^2}{4}\right) \Esp[(Y-\mu)^4] + o\left(\Esp[(Y-\mu)^4]\right) \\
=& \left(f'(\mu)\right)^2 \sigma^2 + 3 \sigma^4 \left(\frac{f'(\mu) f'''(\mu)}{3} + \frac{\left(f''(\mu)\right)^2}{4}\right) + o\left(\Esp[(Y-\mu)^4]\right) \\
\end{align*}

\bigskip

\textbf{Application}:  exponential transformation (\(f = \exp\))
\begin{align*}
\Esp[\exp(Y)] &\approx \exp(\mu)\left(1 + \frac{\sigma^2}{2}\right) \\
\Var[\exp(Y)] &\approx \exp(2\mu)\left(\sigma^2 + \frac{7}{4} \sigma^4\right) \\
\end{align*}

\textbf{Illustration}: 
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
n <- 1e4
mu <- 0.1
sigma2 <- 0.1
X <- rnorm(n, mean = mu, sd = sqrt(sigma2))
fX <- exp(X)
\end{lstlisting}

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
## first order
c(error_mean = mean(fX) - exp(mu), 
  errorPC_mean = 100*(mean(fX) - exp(mu))/mean(fX))
c(error_var = var(fX) - exp(2*mu)*sigma2, 
  errorPC_var = 100*(var(fX) - exp(2*mu)*sigma2)/var(fX))
\end{lstlisting}

\begin{verbatim}
 error_mean errorPC_mean 
 0.05783048   4.97252058
 error_var errorPC_var 
0.02343271 16.09687872
\end{verbatim}

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
## second order
c(mean = mean(fX),
  error_mean = mean(fX) - exp(mu)*(1+sigma2/2), 
  errorPC_mean = 100*(mean(fX) - exp(mu)*(1+sigma2/2))/mean(fX))
c(var = var(fX),
  error_var = var(fX) - exp(2*mu)*(sigma2 + (7/4)*sigma2^2), 
  errorPC_var = 100*(var(fX) - exp(2*mu)*(sigma2 + (7/4)*sigma2^2))/var(fX))
\end{lstlisting}

\begin{verbatim}
        mean   error_mean errorPC_mean 
 1.163001402  0.002571938  0.221146614
        var   error_var errorPC_var 
0.145572982 0.002058158 1.413832496
\end{verbatim}

\subsection{Two independent groups}
\label{sec:org849702e}

\textbf{Theory}: consider two groups \(G=0\) and \(G=1\) for which we want to compare
the percentage difference in outcome \(Y\). Our parameter of interest
is:
\begin{align*}
\frac{\Esp[Y|G=1]-\Esp[Y|G=0]}{\Esp[Y|G=0]} = \gamma
\end{align*}
and we assume that on the original scale:
\begin{align*}
\Var[Y] = \Var[Y|G=1]  = \Var[Y|G=0] = \sigma_Y^2
\end{align*}
and
\begin{align*}
\Esp[Y|G=0] = \alpha_Y
\end{align*}

\bigskip

We only assume that the outcome is normally distribution after log
transformation, i.e. \(\log(Y) \sim
\Gaus\left(a_0,s^2_0\right)\) in the first group
and \(\log(Y) \sim
\Gaus\left(a_1,s^2_1\right)\). We can use the
delta method to identify these parameters:
\begin{align*}
\alpha_Y &= \exp(a_0)\left(1 + \frac{s^2_0}{2}\right) \\
\sigma^2_Y &= \exp(2 a_0)\left(s^2_0 + \frac{7}{4}s^4_0\right) \\
\alpha_Y (\gamma+1) &= \exp(a_1)\left(1 + \frac{s^2_1}{2}\right) \\
\sigma^2_Y &= \exp(2 a_1)\left(s^2_1 + \frac{7}{4}s^4_1\right)
\end{align*}
i.e.
\begin{align*}
\frac{\alpha^2_Y}{\sigma_Y^2} &= \frac{\left(1-\frac{s_0^2}{2}\right)^2}{s^2_0 + \frac{7}{4}s^4_0}  \\
a_0 &= \frac{1}{2}\log\left(\frac{\sigma^2_Y}{\left(s^2_0 + \frac{7}{4}s^4_0\right)}\right) \\
\frac{\alpha^2_Y(\gamma+1)^2}{\sigma_Y^2} &= \frac{\left(1-\frac{s_1^2}{2}\right)^2}{s^2_1 + \frac{7}{4}s^4_1}  \\
a_1 &= \frac{1}{2}\log\left(\frac{\sigma^2_Y}{\left(s^2_1 + \frac{7}{4}s^4_1\right)}\right) 
\end{align*}
The first and third equation can be solved numerically.

\bigskip

\textbf{Illustration}:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
alpha_Y <- 1.15
sigma2_Y <- 0.15

s <- uniroot(function(x){alpha_Y^2/sigma2_Y - (1+x/2)^2/(x+x^2*7/4)},
			   interval = c(0,1))$root
a <- log(sigma2_Y/(s+s^2*7/4))/2
c(a = a, s = s)
\end{lstlisting}

\begin{verbatim}
         a          s 
0.08802784 0.10608948
\end{verbatim}



We can check that:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
c(exp(a)*(1+s/2), exp(2*a)*(s+s^2*7/4))
\end{lstlisting}

\begin{verbatim}
[1] 1.149944 0.150000
\end{verbatim}

i.e.
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
Z <- rnorm(1e4, mean=a, sd = sqrt(s))
mean(exp(Z))
var(exp(Z))
\end{lstlisting}

\begin{verbatim}
[1] 1.152237
[1] 0.1496768
\end{verbatim}

\textbf{Note}: an alternative approach is to use a log-normal distribution with
parameters:
\begin{align*}
s^2 =&\log\left(1+\frac{\sigma^2}{\alpha^2}\right) \\
a =&\log(\alpha) - \frac{s^2}{2} 
\end{align*}
Here it gives:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
s <- log(1+sigma2_Y/alpha_Y^2)
a <- log(alpha_Y) - s/2
c(a = a, s = s)
\end{lstlisting}

\begin{verbatim}
         a          s 
0.08604307 0.10743775
\end{verbatim}

We can check that:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
exp(a + s/2) - alpha_Y
(exp(s)-1)*exp(2*a + s) - sigma2_Y
\end{lstlisting}

\begin{verbatim}
[1] 0
[1] -5.551115e-17
\end{verbatim}

and
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
Y <- rlnorm(1e4, meanlog=a, sdlog = sqrt(s))
mean(Y)
var(Y)
\end{lstlisting}

\begin{verbatim}
[1] 1.146438
[1] 0.1462818
\end{verbatim}
\end{document}