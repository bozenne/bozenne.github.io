% Created 2022-08-30 ti 19:03
% Intended LaTeX compiler: pdflatex
\documentclass[12pt]{article}

%%%% settings when exporting code %%%% 

\usepackage{listings}
\lstdefinestyle{code-small}{
backgroundcolor=\color{white}, % background color for the code block
basicstyle=\ttfamily\small, % font used to display the code
commentstyle=\color[rgb]{0.5,0,0.5}, % color used to display comments in the code
keywordstyle=\color{black}, % color used to highlight certain words in the code
numberstyle=\ttfamily\tiny\color{gray}, % color used to display the line numbers
rulecolor=\color{black}, % color of the frame
stringstyle=\color[rgb]{0,.5,0},  % color used to display strings in the code
breakatwhitespace=false, % sets if automatic breaks should only happen at whitespace
breaklines=true, % sets automatic line breaking
columns=fullflexible,
frame=single, % adds a frame around the code (non,leftline,topline,bottomline,lines,single,shadowbox)
keepspaces=true, % % keeps spaces in text, useful for keeping indentation of code
literate={~}{$\sim$}{1}, % symbol properly display via latex
numbers=none, % where to put the line-numbers; possible values are (none, left, right)
numbersep=10pt, % how far the line-numbers are from the code
showspaces=false,
showstringspaces=false,
stepnumber=1, % the step between two line-numbers. If it's 1, each line will be numbered
tabsize=1,
xleftmargin=0cm,
emph={anova,apply,class,coef,colnames,colNames,colSums,dim,dcast,for,ggplot,head,if,ifelse,is.na,lapply,list.files,library,logLik,melt,plot,require,rowSums,sapply,setcolorder,setkey,str,summary,tapply},
aboveskip = \medskipamount, % define the space above displayed listings.
belowskip = \medskipamount, % define the space above displayed listings.
lineskip = 0pt} % specifies additional space between lines in listings
\lstset{style=code-small}
%%%% packages %%%%%

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp}
\usepackage{color}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage{longtable}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{changes}
\usepackage{pdflscape}
\usepackage{geometry}
\usepackage[normalem]{ulem}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{array}
\usepackage{ifthen}
\usepackage{hyperref}
\usepackage{natbib}
\RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
\renewcommand{\baselinestretch}{1.1}
\geometry{top=1cm}
\usepackage{titlesec}
\usepackage{etoolbox}

\makeatletter
\patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
\patchcmd{\ttlh@hang}{\noindent}{}{}{}
\makeatother
\RequirePackage{colortbl} % arrayrulecolor to mix colors
\definecolor{myorange}{rgb}{1,0.2,0}
\definecolor{mypurple}{rgb}{0.7,0,8}
\definecolor{mycyan}{rgb}{0,0.6,0.6}
\newcommand{\lightblue}{blue!50!white}
\newcommand{\darkblue}{blue!80!black}
\newcommand{\darkgreen}{green!50!black}
\newcommand{\darkred}{red!50!black}
\definecolor{gray}{gray}{0.5}
\hypersetup{
citecolor=[rgb]{0,0.5,0},
urlcolor=[rgb]{0,0,0.5},
linkcolor=[rgb]{0,0,0.5},
}
\newenvironment{note}{\small \color{gray}\fontfamily{lmtt}\selectfont}{\par}
\newenvironment{activity}{\color{orange}\fontfamily{qzc}\selectfont}{\par}
\RequirePackage{pifont}
\RequirePackage{relsize}
\newcommand{\Cross}{{\raisebox{-0.5ex}%
{\relsize{1.5}\ding{56}}}\hspace{1pt} }
\newcommand{\Valid}{{\raisebox{-0.5ex}%
{\relsize{1.5}\ding{52}}}\hspace{1pt} }
\newcommand{\CrossR}{ \textcolor{red}{\Cross} }
\newcommand{\ValidV}{ \textcolor{green}{\Valid} }
\usepackage{stackengine}
\usepackage{scalerel}
\newcommand\Warning[1][3ex]{%
\renewcommand\stacktype{L}%
\scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
\xspace
}
\newcommand\Rlogo{\textbf{\textsf{R}}\xspace} %
\RequirePackage{fancyvrb}
\DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
\RequirePackage{enumitem} % better than enumerate
\RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
\RequirePackage{capt-of} %
\RequirePackage{caption} % newlines in graphics
\RequirePackage{tikz-cd} % graph
\RequirePackage{booktabs} % for nice lines in table (e.g. toprule, bottomrule, midrule, cmidrule)
\RequirePackage{amsmath}
\RequirePackage{algorithm}
\RequirePackage[noend]{algpseudocode}
\RequirePackage{dsfont}
\RequirePackage{amsmath,stmaryrd,graphicx}
\RequirePackage{prodint} % product integral symbol (\PRODI)
\usepackage{ifthen}
\usepackage{xifthen}
\usepackage{xargs}
\usepackage{xspace}
\newcommand\defOperator[7]{%
\ifthenelse{\isempty{#2}}{
\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
}{
\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
}
}
\newcommand\defUOperator[5]{%
\ifthenelse{\isempty{#1}}{
#5\left#3 #2 \right#4
}{
\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
}
}
\newcommand{\defBoldVar}[2]{
\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
}
\newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
\newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
\newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
\newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
\newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
\newcommandx\logLikelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
\newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
\newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
\newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
\newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
\newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
\newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
\newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
\newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
\newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
\newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
\newcommandx\Hypothesis[2][1=,2=]{
\ifthenelse{\isempty{#1}}{
\mathcal{H}
}{
\ifthenelse{\isempty{#2}}{
\mathcal{H}_{#1}
}{
\mathcal{H}^{(#2)}_{#1}
}
}
}
\newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
\ifthenelse{\isempty{#3}}{
\frac{#4 #1}{#4 #2}
}{
\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
}
}
\newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
\newcommandx\ddpartial[3][1=,2=,3=]{
\ifthenelse{\isempty{#3}}{
\frac{\partial^{2} #1}{\partial #2^2}
}{
\frac{\partial^2 #1}{\partial #2\partial #3}
}
}
\newcommand\Real{\mathbb{R}}
\newcommand\Rational{\mathbb{Q}}
\newcommand\Natural{\mathbb{N}}
\newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
\newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
\newcommand\half{\frac{1}{2}}
\newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
\newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
\newcommand\Veta{\boldsymbol{\eta}}
\newcommand\VX{\mathbf{X}}
\newcommand\sample{\chi}
\newcommand\Hspace{\mathcal{H}}
\newcommand\Tspace{\mathcal{T}}
\author{Brice Ozenne}
\date{\today}
\title{Partial correlation in linear models}
\hypersetup{
 colorlinks=true,
 pdfauthor={Brice Ozenne},
 pdftitle={Partial correlation in linear models},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 27.2 (Org mode 9.5.2)},
 pdflang={English}
 }
\begin{document}

\maketitle

\section{Summary}
\label{sec:org3978e17}

This document starts by presenting how to extract from a (univariate)
linear regression model partial correlation coefficients. It also
precise what type of "partial" (i.e. adjusted on which covariate) we
get. When having multiple measurements of pairs of variables, various
technics to estimate (partial) correlations are being compared.

\section{Illustration}
\label{sec:orgfcda72e}

For illustration we will use the following packages:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
library(LMMstar);library(mvtnorm);library(ggplot2);library(nlme)
LMMstar.options(method.numDeriv = "Richardson",
		columns.confint = c("estimate","se","statistic","df","p.value"))
\end{lstlisting}

and dataset \citep{bland1995calculating}:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
data("bland1995", package = "rmcorr")
bland1995$Subject <- as.factor(bland1995$Subject)
head(bland1995)
\end{lstlisting}

\begin{verbatim}
  Subject   pH PacO2
1       1 6.68  3.97
2       1 6.53  4.12
3       1 6.43  4.09
4       1 6.33  3.97
5       2 6.85  5.27
6       2 7.06  5.37
\end{verbatim}


The aim is to relate intramural pH and PaCO2 using eight subjects:

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
gg <- ggplot(bland1995, aes(x = pH, y = PacO2,
			    group = Subject, color = Subject))
gg <- gg + geom_point() + geom_smooth(method = "lm", se = FALSE)
gg
\end{lstlisting}

\begin{center}
\includegraphics[trim={0 0 0 0},width=1\textwidth]{./figures/gg-describe-dataset.pdf}
\end{center}


\clearpage

\section{Partial partial in multiple linear regression}
\label{sec:orga67eef6}

Consider the linear model:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
e.lmm <- lmm(pH ~ Subject + PacO2, data = bland1995)
eTable.lmm <- model.tables(e.lmm)
eTable.lmm
\end{lstlisting}

\begin{verbatim}
              estimate         se df      lower       upper      p.value
(Intercept)  6.9298543 0.12946898 38  6.6677580  7.19195056 0.000000e+00
Subject2     0.7046113 0.07735488 38  0.5480145  0.86120804 4.277623e-11
Subject3     0.9500127 0.06109545 38  0.8263314  1.07369394 0.000000e+00
Subject4     0.9715577 0.07350906 38  0.8227464  1.12036905 8.881784e-16
Subject5     0.8603817 0.05839543 38  0.7421663  0.97859708 0.000000e+00
Subject6     0.9264284 0.06599450 38  0.7928295  1.06002730 0.000000e+00
Subject7     0.6921056 0.10490935 38  0.4797277  0.90448342 8.670218e-08
Subject8     0.7033361 0.06157141 38  0.5786913  0.82798087 7.460699e-14
PacO2       -0.1083230 0.02989281 38 -0.1688379 -0.04780822 8.471081e-04
\end{verbatim}

The F-statistic testing the effect of each factor:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
anova(e.lmm)
\end{lstlisting}

\begin{verbatim}
	     Multivariate Wald test 

  F-statistic       df p.value    
1      48.247 (7,38.0)  <0.001 ***
2      13.131 (1,38.0)  <0.001 ***
\end{verbatim}


equal the Wald-statistic squared (divided by 1, the number of parameters)
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
Wald <- eTable.lmm["PacO2","estimate"]/eTable.lmm["PacO2","se"]
Wald^2
\end{lstlisting}

\begin{verbatim}
[1] 13.13132
\end{verbatim}


This F-statistic is also related to the sum of squares
(ANOVA). Consider a model with a single regressor:
\[ Y = X\beta + \varepsilon\text{, } \varepsilon\sim\Gaus(0,\sigma^2)\]

where we would have centered the outcome \(Y\). Here we denote by
\(X\) the design matrix, \(n\) the number of observations and \(p=1\)
the number of coefficients, \(H = X (X\trans{X})^{-1} \trans{X}\) the
hat matrix and \(\widehat{\beta} = (X\trans{X})^{-1} \trans{X}Y\) the
OLS estimator of the regression coefficients.
\begin{align*}
\Var(Y) = Y\trans{Y} =& YH\trans{Y} + Y(1-H)\trans{Y} \\
SST =& SSR + SSE \\
    =& \hat{\beta} (X\trans{X}) \trans{\hat{\beta}} + Y (1-H) \trans{Y} \\
    =& \sigma^2 (\hat{\beta} \Sigma^{-1}_{\hat{\beta}} \trans{\hat{\beta}} + n-p) \\
\end{align*}
Introducing \(MSSR = SSR/1\) and \(MSSE = SSE/(n-p)\), we obtain that:
\begin{align*}
\frac{MSSR}{MSSE} = \frac{\hat{\beta}^2}{\Sigma_{\hat{\beta}}} = Wald^2
\end{align*}

So the F-statistic equals the ratio of the residual sum of squared
(normalized by their degrees of freedom). We can check that this extends to multiple regression using the
usual anova table:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
anova(lm(pH ~ Subject + PacO2, data = bland1995))
\end{lstlisting}

\begin{verbatim}
Analysis of Variance Table

Response: pH
          Df  Sum Sq Mean Sq F value    Pr(>F)    
Subject    7 2.86484 0.40926  46.600 < 2.2e-16 ***
PacO2      1 0.11532 0.11532  13.131 0.0008471 ***
Residuals 38 0.33373 0.00878                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}


\Warning Since \Rlogo output type 1 anova only the last and second to
last line are relevant. The first line (\texttt{Subject}) is for a model
without \texttt{PacO2} so it should be expected that the F-value does not
match with the one of \texttt{Subject} in a model with \texttt{PacO2}.

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
sigma2 <- as.double(sigma(e.lmm))
beta <- eTable.lmm["PacO2","estimate"]
sigma_beta <- eTable.lmm["PacO2","se"]
c(MSSE = sigma2, MSSR = sigma2 * beta^2 /sigma_beta^2)
\end{lstlisting}

\begin{verbatim}
       MSSE        MSSR 
0.008782435 0.115324959
\end{verbatim}



Finally the \(R^2\) is defined as the proportion of variance explained, i.e.:
\begin{align*}
R^2 =& \frac{SSR}{SSR + SSE} \\
    =& \frac{1}{1 + SSE/SSR} \\
    =& \frac{1}{1 + (n-p)/(\beta^2/\sigma^2_\beta)} \\
    = \frac{Wald^2}{Wald^2 + n-p}
\end{align*}

So the partial correlation coefficient is the square root of that
quantity, with sign the sign of the test statistic:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
df <- eTable.lmm["PacO2","df"]
sign(Wald)*sqrt(Wald^2/(Wald^2+df))
\end{lstlisting}

\begin{verbatim}
[1] -0.5067697
\end{verbatim}


which matches exactly the partial correlation coefficient when \textbf{both}
outcome are adjusted for \texttt{Subject}:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
e.partialCor <- partialCor(list(pH ~ Subject, PacO2 ~ Subject),
			   data = bland1995)
print(e.partialCor, digit = 5)
\end{lstlisting}

\begin{verbatim}
		Partial correlation 

              estimate    se   df lower  upper p.value
rho(pH,PacO2)   -0.507 0.125 25.7 -0.71 -0.225 0.00178

   Note: estimate, standard error, confidence interval have been back-transformed (rho parameters with tanh).
\end{verbatim}


Similar values can be obtained using dedicated packages, e.g.:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
library(rmcorr)
rmcorr(Subject, PacO2, pH, bland1995)$r
\end{lstlisting}

\begin{verbatim}
[1] -0.5067697
\end{verbatim}


\clearpage

\section{Partial partial with repeated measurements}
\label{sec:org8571f8d}

There are several references on the subject
\citep{bland1995calculating,Lipsitz2001partial,bakdash2017repeated,shan2020correlation}. We
will focus on the mixed model approach. The idea is to jointly model
the variance and covariance of all measurements under appropriate
constrains. For instance denoting one measurement \(X\) and the other
measurement \(Y\), both indexed by time \(t\), our target parameter
may be \(\rho = cor(X(t),Y(t))\) (marginal) assumed independent of \(t\) while
\(X\) and \(Y\) may or may not be stationnary. Another target
parameter could be the correlation between a de-noised version of
\(X\) and \(Y\), where we have for instance removed
individual-specific variations (conditional).

\subsection{Illustration}
\label{sec:org877187b}

Let's illustrate \(\rho\) and \(r\) on an example with 3 timepoints,
\(r=0.8\), and 250 individuals:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
n.time <- 3
n.id <- 250
Sigma <- matrix(c(1,0.8,0.8,1),2,2)
Sigma
\end{lstlisting}

\begin{verbatim}
     [,1] [,2]
[1,]  1.0  0.8
[2,]  0.8  1.0
\end{verbatim}


\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
set.seed(11)
df.W <- data.frame(id = unlist(lapply(1:n.id, rep, n.time)),
		   time = rep(1:n.time,n.id),
		   rmvnorm(n.time*n.id, mean = c(3,3), sigma = Sigma)
		   )
head(df.W)
\end{lstlisting}

\clearpage

We introduce random effects to impose a constant correlation
within-individuals for \(X\) and for \(Y\):
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
sd.id <- 1.5
df.W$X1 <- df.W$X1 + rnorm(n.id, sd = sd.id/4)[df.W$id]
df.W$X2 <- df.W$X2 + rnorm(n.id, sd = sd.id)[df.W$id]
df.W$id <- as.factor(df.W$id)
df.L <- reshape2::melt(df.W, id.vars = c("id","time")) 
df.L$time2 <- as.factor(as.numeric(as.factor(paste(df.L$variable,df.L$time,sep="."))))
\end{lstlisting}

This will lead to the following correlation structure:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
Sigma.GS <- as.matrix(bdiag(Sigma,Sigma,Sigma))[c(1,3,5,2,4,6),c(1,3,5,2,4,6)]
Sigma.GS[1:3,1:3] <- Sigma.GS[1:3,1:3] + (sd.id/4)^2
Sigma.GS[4:6,4:6] <- Sigma.GS[4:6,4:6] + sd.id^2
cov2cor(Sigma.GS)
\end{lstlisting}

\begin{verbatim}
          [,1]      [,2]      [,3]      [,4]      [,5]      [,6]
[1,] 1.0000000 0.1232877 0.1232877 0.4155056 0.0000000 0.0000000
[2,] 0.1232877 1.0000000 0.1232877 0.0000000 0.4155056 0.0000000
[3,] 0.1232877 0.1232877 1.0000000 0.0000000 0.0000000 0.4155056
[4,] 0.4155056 0.0000000 0.0000000 1.0000000 0.6923077 0.6923077
[5,] 0.0000000 0.4155056 0.0000000 0.6923077 1.0000000 0.6923077
[6,] 0.0000000 0.0000000 0.4155056 0.6923077 0.6923077 1.0000000
\end{verbatim}


We can now estimate two types of correlation: marginal and conditional
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
e.LMMstar <- partialCor(c(X1,X2) ~ 1, repetition = ~ time|id, data = df.W, heterogeneous = 0.5)
e.LMMstar
\end{lstlisting}

\begin{verbatim}
		Partial correlation 

               estimate     se   df lower upper p.value
rho(1.X1,1.X2)    0.427 0.0346 34.8 0.356 0.493 6.5e-13
r(1.X1,1.X2)      0.790 0.0672 66.4 0.656 0.925 0.0e+00
	----------------------------------------------------
	rho: marginal correlation 
	r  : correlation conditional on the individual
\end{verbatim}


The conditional is very close to what other packages output:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
rmcorr(id, X1, X2, df.W)$r
\end{lstlisting}

\begin{verbatim}
[1] 0.7941749
\end{verbatim}


Here the modeled correlation matrix is:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
Sigma <- sigma(attr(e.LMMstar,"lmm"))
Rho <- cov2cor(Sigma)
Rho
\end{lstlisting}

\begin{verbatim}
            1.X1        2.X1        3.X1        1.X2        2.X2        3.X2
1.X1  1.00000000  0.06545230  0.06545230  0.42652595 -0.00432106 -0.00432106
2.X1  0.06545230  1.00000000  0.06545230 -0.00432106  0.42652595 -0.00432106
3.X1  0.06545230  0.06545230  1.00000000 -0.00432106 -0.00432106  0.42652595
1.X2  0.42652595 -0.00432106 -0.00432106  1.00000000  0.68836567  0.68836567
2.X2 -0.00432106  0.42652595 -0.00432106  0.68836567  1.00000000  0.68836567
3.X2 -0.00432106 -0.00432106  0.42652595  0.68836567  0.68836567  1.00000000
\end{verbatim}


From which the conditional correlation can be deduced:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
Rho[1,4]/sqrt((1-Rho[1,2])*(1-Rho[4,5]))
\end{lstlisting}

\begin{verbatim}
[1] 0.7903548
\end{verbatim}


or equivalently:
\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
Sigma[1,4]/sqrt((Sigma[1,1]-Sigma[1,2])*(Sigma[4,4]-Sigma[4,5]))
\end{lstlisting}

\begin{verbatim}
[1] 0.7903548
\end{verbatim}

\subsection{Simulation study}
\label{sec:orge9afdbd}

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
library(data.table)

n.id <- 100
warper <- function(n){
  df.W <- data.frame(id = unlist(lapply(1:n.id, rep, n.time)),
		     time = rep(1:n.time,n.id),
		     rmvnorm(n.time*n.id, mean = c(3,3), sigma = Sigma)
		     )
  df.W$X1 <- df.W$X1 + rnorm(n.id, sd = sd.id/4)[df.W$id]
  df.W$X2 <- df.W$X2 + rnorm(n.id, sd = sd.id)[df.W$id]
  df.W$id <- as.factor(df.W$id)

  res1 <- setNames(c(rmcorr(id, X1, X2, df.W)$r, rmcorr(id, X1, X2, df.W)$CI), c("estimate","lower","upper"))
  res2 <- partialCor(c(X1,X2) ~ 1, repetition = ~ time|id, data = df.W, heterogeneous = 0.5)
  return(rbind(cbind(as.data.frame(as.list(res1)), se = NA, method = "rmcorr"),
	       cbind(res2[2,c("estimate","lower","upper","se")],method="lmm")))
}

ls.res <- pbapply::pblapply(1:101,function(iSim){
  cbind(sim = iSim, warper(100))
})
dt.res <- as.data.table(do.call(rbind, ls.res))
\end{lstlisting}

\lstset{language=r,label= ,caption= ,captionpos=b,numbers=none}
\begin{lstlisting}
ggplot(dt.res,aes(x=method,y=estimate))+ geom_boxplot()
\end{lstlisting}

\begin{center}
\includegraphics[trim={0 0 0 0},width=1\textwidth]{./figures/gg-comp-corEstimator.pdf}
\end{center}


\section{Reference}
\label{sec:orgb946f09}
\begingroup
\renewcommand{\section}[2]{}
\bibliographystyle{apalike}
\bibliography{bibliography} 
\endgroup

\appendix \titleformat{\section}
{\normalfont\Large\bfseries}{}{1em}{Appendix~\thesection:~}

\renewcommand{\thefigure}{\Alph{figure}}
\renewcommand{\thetable}{\Alph{table}}
\renewcommand{\theequation}{\Alph{equation}}

\setcounter{figure}{0}    
\setcounter{table}{0}    
\setcounter{equation}{0}    
\end{document}