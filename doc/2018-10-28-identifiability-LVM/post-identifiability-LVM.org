#+TITLE: Latent variable model and identifiability
#+Author: Brice Ozenne

#+BEGIN_SRC R :exports none :results both :session *R* :cache no
path <- "~/Documents/GitHub/bozenne.github.io/doc/2018-10-28-identifiability-LVM/"
setwd(path)
#+END_SRC

#+RESULTS:
: /home/brice/Documents/GitHub/bozenne.github.io/doc/2018-10-28-identifiability-LVM

#+LaTeX: \lstset{style=code-tiny}

* A necessary condition for identifiability
One way to assess identifiability of a model is to count the number of
parameters vs. the number of sufficient statistics brought by the
data. If the number of parameters in the model exceed the number of
sufficient statistics brought by the data the model is not
identifiable.

** Example in univariate linear models
Assuming normaly distributed variables:

\bigskip

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
data <- data.frame(Y = rnorm(10),
                   X = rnorm(10))
#+END_SRC

\bigskip

the sufficient statistics are the mean, variance, and covariance. This
means that knowing the mean and the variance, I can simulate new data
following the same law as my observed data. When considering only the
outcome, I need at least two observations to fit a linear model:

\bigskip

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## can only estimate the mean of Y
eY.1 <- lm(Y ~ 1, data = data[1,, drop = FALSE])
summary(eY.1)$coef
sigma(eY.1)
#+END_SRC

#+RESULTS:
:               Estimate Std. Error t value Pr(>|t|)
: (Intercept) 0.01874617        NaN     NaN      NaN
: [1] NaN

\clearpage

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## can estimate both the mean and variance of Y
eY.2 <- lm(Y ~ 1, data = data[1:2,, drop = FALSE])
summary(eY.2)$coef
sigma(eY.2)
#+END_SRC

#+RESULTS:
:                Estimate Std. Error    t value  Pr(>|t|)
: (Intercept) -0.08275319  0.1014994 -0.8153075 0.5645487
: [1] 0.1435418


\bigskip

If I also want to adjust on X, I now also need to estimate the
covariance between X and Y. So I need at least one more observation:

\bigskip

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## can only estimate the mean of Y and its covariance with X
eXY.2 <- lm(Y ~ X, data = data[1:2,, drop = FALSE])
summary(eXY.2)$coef
sigma(eXY.2)
#+END_SRC

#+RESULTS:
:               Estimate Std. Error t value Pr(>|t|)
: (Intercept) -0.6276732        NaN     NaN      NaN
: X            0.5867049        NaN     NaN      NaN
: [1] NaN

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
## can estimate the mean, variance of Y and its covariance with X
eXY.3 <- lm(Y ~ X, data = data[1:3,, drop = FALSE])
summary(eXY.3)$coef
sigma(eXY.3)
#+END_SRC

#+RESULTS:
:              Estimate Std. Error    t value   Pr(>|t|)
: (Intercept) -1.091006 0.09766722 -11.170647 0.05683890
: X            1.072162 0.12464616   8.601644 0.07368065
: [1] 0.1226233

\clearpage

* Application to latent variable models (lvm)

In a latent variable model things are simular. Because we are interested in modeling the
relationship between variables, usually we focus on the covariance matrix: does the observed
covariance matrix enable to identify the modeled covariance matrix? 

** Example 1: bivariate lvm
Consider the following model:

#+BEGIN_SRC R :exports code :results output :session *R* :cache no
library(lava)

lvm.2Y <- lvm(c(Y, E) ~ eta)
latent(lvm.2Y) <- ~ eta
#+END_SRC

#+RESULTS:

#+BEGIN_SRC R :results output raw drawer  :exports none :session *R* :cache no 
pdf("figures/show-bivariateLVM.pdf")
plot(lvm.2Y, plot.engine = "igraph")
dev.off()
#+END_SRC

#+RESULTS:
:RESULTS:
null device 
          1
:END:

#+ATTR_LATEX: :width 0.5\textwidth
file:./figures/show-bivariateLVM.pdf

This model involves 3 variables (2 observed and 1 latent). We can
write the (full)  *mean vector* and *variance-covariance matrix* between all the variables:
#+BEGIN_EXPORT latex
\begin{align*}
\mu = \begin{bmatrix} 
\mu_Y \\ \mu_\eta \\ \mu_E \\
\end{bmatrix} = \begin{bmatrix} 
\Esp[Y] \\ \Esp[\eta] \\ \Esp[E] \\
\end{bmatrix} 
\qquad 
\Sigma = \begin{bmatrix} 
\sigma_{Y,Y} & \sigma_{Y,\eta} & \sigma_{Y,E} \\ & \sigma_{\eta,\eta} & \sigma_{\eta,E} \\ & & \sigma_{E,E}  \\
\end{bmatrix} = \begin{bmatrix} 
\Var(Y) & \Cov(Y,\eta) & \Cov(Y,E) \\ & \Var(\eta) & \Cov(\eta,E) \\ & & \Var(E)  \\
\end{bmatrix} 
\end{align*}
#+END_EXPORT
Since we don't observed \(\eta\), we cannot estimate its mean and
variance. A common convention is to set its mean to \(0\) and variance
to \(1\) [fn::By default, \texttt{lava} do something else: it sets the
mean of \(Y\), the reference outcome, to 0 and fix its covariance such
that \(\Cov(Y,\eta)=\Var(\eta)\)]. Using this latent variable model, we
also assumed here that \(Y\) is independent of \(E\) given \(\eta\)
(i.e. \(\Cov(Y,\eta)=\frac{\Cov(Y,\eta)\Cov(E,\eta)}{\Var[\eta]}\)). So
at the end of the day, we only have 4 parameters to estimate: 
#+BEGIN_EXPORT latex
\begin{align*}
\theta = \left(\mu_Y,\mu_E, \sigma_{Y,Y}, \sigma_{Y,\eta}, \sigma_{\eta,E}, \sigma_{E,E}\right)
\end{align*}
#+END_EXPORT
\clearpage

The *empirical mean vector* contains two parameters but the *empirical
variance-covariance matrix* only contains three different parameters:
#+BEGIN_EXPORT latex
\begin{align*}
m = 
\begin{bmatrix} 
\overline{Y} \\ \overline{E} \\
\end{bmatrix} 
\qquad
S = 
\begin{bmatrix} 
s_{Y,Y} & s_{Y,E} \\ & s_{E,E} \\
\end{bmatrix} 
\end{align*}
#+END_EXPORT

We can check that in R:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
n <- 1e3
df.2Y <- sim(lvm.2Y, n, latent = FALSE)
cbind(mu=colMeans(df.2Y), vcov = cov(df.2Y))
#+END_SRC

#+RESULTS:
:            mu         Y         E
: Y -0.01663862 2.0403977 0.9651849
: E  0.06287055 0.9651849 1.9554924

Overall:
- \ValidV :: for the mean parameters: the full expectation vector would contain 3
  parameters, one for each variable. We only observe two of them
  (\(Y\) and \(E\)) and by default lava fix the intercept of \(Y\) to
  be 0 so there are only two mean parameters.
- \CrossR :: for the variance-covariance parameters: we have 6
             parameters to estimate (3 variances, 3 covariances) which
             after applying some necessary restriction reduces to 4
             parameters. However we only observe 3 moments. The model
             is therefore not identifiable.
This means that the lvm won't properly converge
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
estimate(lvm(Y ~ eta, E ~ eta, eta[0:1] ~ 1), 
         data = df.2Y)
#+END_SRC

#+RESULTS:
#+begin_example
                    Estimate Std. Error  Z-value  P-value
Measurements:                                            
   Y~eta             1.03678    0.04082 25.39900   <1e-12
   E~eta             0.93001    0.04310 21.57969   <1e-12
Intercepts:                                              
   Y                -0.01664    0.04515 -0.36853   0.7125
   E                 0.06287    0.04420  1.42245   0.1549
Residual Variances:                                      
   Y                 0.96344    0.04249 22.67723         
   E                 1.08861    0.05162 21.08771         
Warning messages:
1: In estimate.lvm(lvm(Y ~ eta, E ~ eta, eta[0:1] ~ 1), data = df.2Y) :
  Near-singular covariance matrix, using pseudo-inverse!
2: In print.lvmfit(x) : Small singular value: 0
3: In print.lvmfit(x) : Singular covariance matrix. Pseudo-inverse used.
#+end_example

The non identifiability come from the fact that the only equation
defining the parameters \(\sigma_{E,eta}\) and \(\sigma_{\eta,\eta}\) is:
#+BEGIN_EXPORT latex
\begin{align*}
\Cov(Y,\eta)=\frac{\Cov(Y,\eta)\Cov(E,\eta)}{\Var[\eta]} = \Cov(Y,\eta)\Cov(E,\eta)
\end{align*}
#+END_EXPORT
which is not identifiable because we only observe \(\Cov(Y,\eta)\) so
\(\Cov(Y,\eta)\) and \(\Cov(E,\eta)\) can take any value as soon as
their product remain constant and equal to \(\Cov(Y,\eta)\). One
solution is to constraint them to be equal:

\bigskip

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
estimate(lvm(Y ~ lambda*eta, E ~ lambda*eta, eta[0:1] ~ 1), 
         data = df.2Y)
#+END_SRC

#+RESULTS:
:                     Estimate Std. Error  Z-value  P-value
: Measurements:                                            
:    Y~eta             0.98195    0.03569 27.51623   <1e-12
: Intercepts:                                              
:    Y                -0.01664    0.04515 -0.36853   0.7125
:    E                 0.06287    0.04420  1.42245   0.1549
: Residual Variances:                                      
:    Y                 1.07414    0.07321 14.67183         
:    E                 0.98932    0.07078 13.97739

\clearpage

** Example 2: bivariate lvm with group effect

Let's modify the previous model by adding an exogenous variable
affecting the latent variable:

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
lvm.2YX <- lvm(Y[0.5:0.5] ~ eta, E[1.25:2] ~ 3*eta,
              eta[0:1] ~ 0.25*X, X[0:1] ~ 1)
latent(lvm.2YX) <- ~ eta
#+END_SRC

#+RESULTS:

#+LaTeX: \vspace{-1cm}

#+BEGIN_SRC R :results output raw drawer  :exports none :session *R* :cache no 
pdf("figures/show-bivariateLVM-Age.pdf")
plot(lvm.2YX, plot.engine = "igraph")
dev.off()
#+END_SRC

#+RESULTS:
:RESULTS:
null device 
          1
:END:

#+ATTR_LATEX: :width 0.5\textwidth
file:./figures/show-bivariateLVM-Age.pdf

#+LaTeX: \vspace{-1cm}

This model involves 4 variables (3 observed and 1 latent). We can
write the (full)  *mean vector* and *variance-covariance matrix* between all the variables:
#+BEGIN_EXPORT latex
\begin{align*}
\mu &= \begin{bmatrix} 
\mu_Y \\ \mu_\eta \\ \mu_E \\ \mu_{X} \\
\end{bmatrix} = \begin{bmatrix} 
\Esp[Y] \\ \Esp[\eta] \\ \Esp[E] \\ \Esp[X] \\
\end{bmatrix} 
\\
\Sigma &= \begin{bmatrix} 
\sigma_{Y,Y} & \sigma_{Y,\eta} & \sigma_{Y,E} & \sigma_{Y,X} \\ & \sigma_{\eta,\eta} & \sigma_{\eta,E} & \sigma_{\eta,X} \\ & & \sigma_{E,E} & \sigma_{E,X} \\ &&& \sigma_{X,X}  \\
\end{bmatrix} = \begin{bmatrix} 
\Var(Y) & \Cov(Y,\eta) & \Cov(Y,E) & \Cov(Y,X) \\ & \Var(\eta) & \Cov(\eta,E) & \Cov(\eta,X) \\ & & \Var(E) & \Cov(E,X)  \\ & & & \Var[X]\\
\end{bmatrix} 
\end{align*}
#+END_EXPORT
As before we will constrain the mean of the latent variable to be 0
and its variance to be 1. Furthermore, conditional on the latent
variable, \(Y\), \(E\), and \(\eta\) are independent of each other. So
\( \Cov(Y,E) \), \( \Cov(Y,X) \), and \( \Cov(E,X) \) are not "real"
parameters. So we only need to estimate 9 parameters:
#+BEGIN_EXPORT latex
\begin{align*}
\theta = \left( \mu_Y, \mu_E, \mu_X, \sigma_{Y,Y}, \sigma_{E,E}, \sigma_{X,X}, \sigma_{Y,\eta}, \sigma_{E,\eta}, \sigma_{\eta,X} \right)
\end{align*}
#+END_EXPORT
The *empirical mean vector* and *empirical variance-covariance matrix*
also contain 9 parameters:
#+BEGIN_EXPORT latex
\begin{align*}
m = \begin{bmatrix} 
\overline{Y} \\ \overline{E} \\ \overline{X} \\
\end{bmatrix} 
\qquad
S = \begin{bmatrix} 
s_{Y,Y} & s_{Y,E} & s_{Y,X} \\ & s_{E,E} & s_{E,X} \\ & & s_{X,X} \\
\end{bmatrix} 
\end{align*}
#+END_EXPORT

or in R:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df.2YX <- sim(lvm.2YX, n = 1e4, latent = FALSE)
cbind(mu=colMeans(df.2YX), vcov = cov(df.2YX))
#+END_SRC

#+RESULTS:
:            mu         Y          E         X
: Y  0.47355535 1.5787540  3.2020009 0.2519949
: E  1.17255908 3.2020009 11.5908969 0.7315259
: X -0.02028518 0.2519949  0.7315259 0.9781732

So the model satisfy one necessary condition for being
identifiable. This condition is however not sufficient to ensure
identifiability but is easier to check than the NSC (nessary and
sufficient condition). To check the NSC we need to write down the
equations relating the empirical and the theoretical moments. To make
things a little simpler we will assume that \(X\) has mean 0 and
variance 1. We obtain the model:
#+BEGIN_EXPORT latex
\begin{align*}
Y &= \mu_Y + \sigma_{Y,\eta} \eta + \varepsilon_Y \qquad \varepsilon_Y\sim\Gaus[0,\sigma_{Y,Y}] \\
E &= \mu_E + \sigma_{E,\eta} \eta + \varepsilon_E \qquad \varepsilon_Y\sim\Gaus[0,\sigma_{E,E}]\\
\eta &= \sigma_{\eta,X} X + \xi_\eta \qquad \varepsilon_\eta\sim\Gaus[0,1]
\end{align*}
#+END_EXPORT
we get:
#+BEGIN_EXPORT latex
\begin{align*}
\left\{
\begin{array}{l}
s_{Y,Y} = \sigma_{Y,\eta}^2(1+\sigma^2_{\eta,X}) + \sigma_{Y,Y} \\
s_{E,E} = \sigma_{E,\eta}^2(1+\sigma^2_{\eta,X}) + \sigma_{E,E} \\
s_{Y,E} = \sigma_{Y,\eta}\sigma_{E,\eta}(1+\sigma^2_{\eta,X}) \\
s_{Y,X} = \sigma_{Y,\eta}\sigma_{\eta,X} \\
s_{E,X} = \sigma_{E,\eta}\sigma_{\eta,X} 
\end{array}
\right.
\qquad
\left\{
\begin{array}{l}
\sigma_{\eta,X} = \sqrt{\frac{s_{Y,X}s_{E,X}}{s_{Y,E}-s_{Y,X}s_{E,X}}} \\
\sigma_{Y,\eta} = \frac{s_{Y,X}}{\sigma_{\eta,X}} \\
\sigma_{E,\eta} = \frac{s_{E,X}}{\sigma_{\eta,X}} \\
\sigma_{Y,Y} = s_{Y,Y} - \sigma_{Y,\eta}^2(1+\sigma^2_{\eta,X}) \\
\sigma_{E,E} = s_{E,E} - \sigma_{E,\eta}^2(1+\sigma^2_{\eta,X}) \\
\end{array}
\right.
\end{align*}
#+END_EXPORT
which we can solve and therefore the model is identifiable. This is
confirmed by the fact that lava is able to estimate the model:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.lvm.2XY <- estimate(lvm(Y~eta,E~eta,eta[0:1]~X), data = df.2YX)
e.lvm.2XY
#+END_SRC

#+RESULTS:
#+begin_example
                    Estimate Std. Error  Z-value  P-value
Measurements:                                            
   Y~eta             1.01882    0.01931 52.76797   <1e-12
   E~eta             2.95758    0.05605 52.76797   <1e-12
Regressions:                                             
   eta~X             0.25286    0.01119 22.59794   <1e-12
Intercepts:                                              
   Y                 0.47878    0.01231 38.90703   <1e-12
   E                 1.18773    0.03324 35.73453   <1e-12
Residual Variances:                                      
   Y                 0.47569    0.03712 12.81639         
   E                 2.29545    0.30930  7.42139
#+end_example

#+BEGIN_SRC R :exports none :results output :session *R* :cache no
lambdaY <- coef(e.lvm.2XY)["Y~eta"]
lambdaE <- coef(e.lvm.2XY)["E~eta"]
sigmaY <-  coef(e.lvm.2XY)["Y~~Y"]
sigmaE <-  coef(e.lvm.2XY)["E~~E"]
betaX <-  coef(e.lvm.2XY)["eta~X"]
sigmaEta <- 1+betaX^2*var(df.2YX$X)

c(
var(df.2YX$Y) - (sigmaY + lambdaY^2 * sigmaEta),
var(df.2YX$E) - (sigmaE + lambdaE^2 * sigmaEta),
cov(df.2YX$Y,df.2YX$E) - (lambdaY * lambdaE * sigmaEta),
cov(df.2YX$Y,df.2YX$X) - (lambdaY * betaX),
cov(df.2YX$E,df.2YX$X) - (lambdaE * betaX)
)
#+END_SRC

#+RESULTS:
:          Y~~Y          E~~E         Y~eta         Y~eta         E~eta 
:  0.0001513835  0.0011043822  0.0003013549 -0.0056229719 -0.0163231485

We can in fact manually estimat the coefficients (here we do REML
estimation instead of ML so the estimated variance will be a bit
larger compared to lava):

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
s_YY <- var(df.2YX$Y)
s_EE <- var(df.2YX$E)
s_YX <- cov(df.2YX$Y,df.2YX$X)
s_EX <- cov(df.2YX$E,df.2YX$X)
s_YE <- cov(df.2YX$Y,df.2YX$E)

ratio <- s_EX / (s_YE - s_YX * s_EX)

manual <- c("eta~X" = sqrt(s_YX * ratio),
            "Y~eta" = s_YX/sqrt(s_YX * ratio),
            "E~eta" = s_EX/sqrt(s_YX * ratio),
            "Y~~Y" = s_YY - s_YX^2/(s_YX * ratio) * (1 + s_YX * ratio),
            "E~~E" =  s_EE - s_EX^2/(s_YX * ratio) * (1 + s_YX * ratio)
            )
rbind(manual = manual,
      lava = coef(e.lvm.2XY)[names(manual)]
      )
#+END_SRC

#+RESULTS:
:            eta~X    Y~eta    E~eta      Y~~Y     E~~E
: manual 0.2471585 1.019568 2.959744 0.4757339 2.295681
: lava   0.2528586 1.018822 2.957578 0.4756863 2.295452

Note that the model is exactly identifiable in the sense that we have
exactly the same number of parameters and moments. Adding an
additional link between age and one outcome would make the model non
identifiable since we would increase by one the number of parameters
(p=10) while still having only 9 moments:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
estimate(lvm(Y~eta+Age,E~eta,eta[0:1]~X), data = df.2YX)
#+END_SRC

#+RESULTS:
#+begin_example
                    Estimate Std. Error  Z-value  P-value
Measurements:                                            
   Y~eta             1.01882    0.01931 52.76797   <1e-12
   E~eta             2.95758    0.05605 52.76797   <1e-12
Regressions:                                             
   eta~X             0.25286    0.01119 22.59794   <1e-12
Intercepts:                                              
   Age               0.47878    0.01231 38.90703   <1e-12
   E                 1.18773    0.03324 35.73453   <1e-12
Residual Variances:                                      
   Y                 0.36434                             
   Age               0.11135                             
   E                 2.29545    0.30930  7.42139         
Warning messages:
1: In sqrt(diag(asVar)) : production de NaN
2: In print.lvmfit(x) : Small singular value: 2.409293e-13
#+end_example

* Reference :noexport:
# help: https://gking.harvard.edu/files/natnotes2.pdf

#+BEGIN_EXPORT latex
\begingroup
\renewcommand{\section}[2]{}
#+END_EXPORT
bibliographystyle:apalike
[[bibliography:bibliography.bib]] 
#+BEGIN_EXPORT latex
\endgroup
#+END_EXPORT

#+BEGIN_EXPORT LaTeX
\appendix
\titleformat{\section}
{\normalfont\Large\bfseries}{}{1em}{Appendix~\thesection:~}

\renewcommand{\thefigure}{\Alph{figure}}
\renewcommand{\thetable}{\Alph{table}}
\renewcommand{\theequation}{\Alph{equation}}

\setcounter{figure}{0}    
\setcounter{table}{0}    
\setcounter{equation}{0}    

\setcounter{page}{1}
#+END_EXPORT

* CONFIG :noexport:
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t

** Display of the document
# ## space between lines
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}

# ## margins
#+LATEX_HEADER:\geometry{top=1cm}

# ## personalize the prefix in the name of the sections
#+LaTeX_HEADER: \usepackage{titlesec}
# ## fix bug in titlesec version
# ##  https://tex.stackexchange.com/questions/299969/titlesec-loss-of-section-numbering-with-the-new-update-2016-03-15
#+LaTeX_HEADER: \usepackage{etoolbox}
#+LaTeX_HEADER: 
#+LaTeX_HEADER: \makeatletter
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\noindent}{}{}{}
#+LaTeX_HEADER: \makeatother

** Color
# ## define new colors
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LaTeX_HEADER: \definecolor{myorange}{rgb}{1,0.2,0}
#+LaTeX_HEADER: \definecolor{mypurple}{rgb}{0.7,0,8}
#+LaTeX_HEADER: \definecolor{mycyan}{rgb}{0,0.6,0.6}
#+LaTeX_HEADER: \newcommand{\lightblue}{blue!50!white}
#+LaTeX_HEADER: \newcommand{\darkblue}{blue!80!black}
#+LaTeX_HEADER: \newcommand{\darkgreen}{green!50!black}
#+LaTeX_HEADER: \newcommand{\darkred}{red!50!black}
#+LaTeX_HEADER: \definecolor{gray}{gray}{0.5}

# ## change the color of the links
#+LaTeX_HEADER: \hypersetup{
#+LaTeX_HEADER:  citecolor=[rgb]{0,0.5,0},
#+LaTeX_HEADER:  urlcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER:  linkcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER: }

** Font
# https://tex.stackexchange.com/questions/25249/how-do-i-use-a-particular-font-for-a-small-section-of-text-in-my-document
#+LaTeX_HEADER: \newenvironment{comment}{\small \color{gray}\fontfamily{lmtt}\selectfont}{\par}
#+LaTeX_HEADER: \newenvironment{activity}{\color{orange}\fontfamily{qzc}\selectfont}{\par}

** Symbols
# ## valid and cross symbols
#+LaTeX_HEADER: \RequirePackage{pifont}
#+LaTeX_HEADER: \RequirePackage{relsize}
#+LaTeX_HEADER: \newcommand{\Cross}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{56}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\Valid}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{52}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\CrossR}{ \textcolor{red}{\Cross} }
#+LaTeX_HEADER: \newcommand{\ValidV}{ \textcolor{green}{\Valid} }

# ## warning symbol
#+LaTeX_HEADER: \usepackage{stackengine}
#+LaTeX_HEADER: \usepackage{scalerel}
#+LaTeX_HEADER: \newcommand\Warning[1][3ex]{%
#+LaTeX_HEADER:   \renewcommand\stacktype{L}%
#+LaTeX_HEADER:   \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
#+LaTeX_HEADER:   \xspace
#+LaTeX_HEADER: }

# # R Software
#+LATEX_HEADER: \newcommand\Rlogo{\textbf{\textsf{R}}\xspace} % 

** Code
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*

# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}

# ## change font size input (global change)
# ## doc: https://ctan.math.illinois.edu/macros/latex/contrib/listings/listings.pdf
#+LATEX_HEADER: \lstdefinestyle{code-tiny}{basicstyle=\ttfamily\footnotesize}
# #+LATEX_HEADER: \lstset{style=code-tiny}
# ## change font size input (local change, put just before BEGIN_SRC)
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output (global change)
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}

** Lists
#+LATEX_HEADER: \RequirePackage{enumitem} % better than enumerate

** Image and graphs
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics

#+LaTeX_HEADER: \RequirePackage{tikz-cd} % graph
# ## https://tools.ietf.org/doc/texlive-doc/latex/tikz-cd/tikz-cd-doc.pdf

** Table
#+LATEX_HEADER: \RequirePackage{booktabs} % for nice lines in table (e.g. toprule, bottomrule, midrule, cmidrule)

** Inline latex
# @@latex:any arbitrary LaTeX code@@


** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}

** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)

# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}

*** Template for shortcut
#+LATEX_HEADER: \usepackage{ifthen}
#+LATEX_HEADER: \usepackage{xifthen}
#+LATEX_HEADER: \usepackage{xargs}
#+LATEX_HEADER: \usepackage{xspace}

#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }

**** Probability
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}

#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}

#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\logLikelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}

**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}

#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}

#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}

#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\partial #2^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 

**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}

#+LATEX_HEADER: \newcommand\Veta{\boldsymbol{\eta}}
#+LATEX_HEADER: \newcommand\VX{\mathbf{X}}


** Notations
