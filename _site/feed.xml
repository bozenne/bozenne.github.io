<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.4">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-10-29T22:54:17+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Biostat at kunru</title><subtitle>Welcome to my professional website. You will find a brief description of my research, teaching material, and information about my consulting activity at NRU.</subtitle><author><name>Brice Ozenne</name></author><entry><title type="html">Inconsistency between F-test and Wald tests</title><link href="http://localhost:4000/jekyll/update/2018/10/29/univariate-vs-multivariate-test.html" rel="alternate" type="text/html" title="Inconsistency between F-test and Wald tests" /><published>2018-10-29T00:00:00+01:00</published><updated>2018-10-29T00:00:00+01:00</updated><id>http://localhost:4000/jekyll/update/2018/10/29/univariate-vs-multivariate-test</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/29/univariate-vs-multivariate-test.html">&lt;p&gt;When testing the effect of a categorical variable with, for instance,
3 categories, one first tests whether any category has an effect. This
is typically done using a F-test in an ANOVA. If significant, one is
often also interested in which level of the categorical variable has
an effect. This can be done fixing a reference level and using a Wald
test to compare the other levels of the variable to the reference
level. However the F-test and the Wald tests may give contradictory
results. This
&lt;a href=&quot;https://bozenne.github.io/doc/Univariate-vs-Multivariate-test/uniVSmult.pdf&quot;&gt;document&lt;/a&gt;
presents a geometrical illustration of when the F-test and Wald test
may disagree.&lt;/p&gt;</content><author><name>Brice Ozenne</name></author><summary type="html">When testing the effect of a categorical variable with, for instance, 3 categories, one first tests whether any category has an effect. This is typically done using a F-test in an ANOVA. If significant, one is often also interested in which level of the categorical variable has an effect. This can be done fixing a reference level and using a Wald test to compare the other levels of the variable to the reference level. However the F-test and the Wald tests may give contradictory results. This document presents a geometrical illustration of when the F-test and Wald test may disagree.</summary></entry><entry><title type="html">Deriving identifiability conditions for a latent variable model</title><link href="http://localhost:4000/jekyll/update/2018/10/28/identifiability-LVM.html" rel="alternate" type="text/html" title="Deriving identifiability conditions for a latent variable model" /><published>2018-10-28T00:00:00+02:00</published><updated>2018-10-28T00:00:00+02:00</updated><id>http://localhost:4000/jekyll/update/2018/10/28/identifiability-LVM</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/28/identifiability-LVM.html">&lt;p&gt;When using the lava package, sometimes the estimation procedure fails
to converge. Often this is because the model is not identifiable and
it is therefore estimation is just not possible (in a unique way). In
such a case the practionner should modify his/her model to make it
identifiable or collect additional data. This
&lt;a href=&quot;https://bozenne.github.io/doc/Identifiability-LVM/LVMindentifiability.pdf&quot;&gt;document&lt;/a&gt;
describes a simple procedure to derive necessary identifiability
conditions for a latent variable model.&lt;/p&gt;</content><author><name>Brice Ozenne</name></author><summary type="html">When using the lava package, sometimes the estimation procedure fails to converge. Often this is because the model is not identifiable and it is therefore estimation is just not possible (in a unique way). In such a case the practionner should modify his/her model to make it identifiable or collect additional data. This document describes a simple procedure to derive necessary identifiability conditions for a latent variable model.</summary></entry><entry><title type="html">Intraclass correlation coefficient (ICC)</title><link href="http://localhost:4000/jekyll/update/2018/10/27/ICC.html" rel="alternate" type="text/html" title="Intraclass correlation coefficient (ICC)" /><published>2018-10-27T00:00:00+02:00</published><updated>2018-10-27T00:00:00+02:00</updated><id>http://localhost:4000/jekyll/update/2018/10/27/ICC</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/27/ICC.html">&lt;p&gt;See &lt;a href=&quot;https://bozenne.github.io/doc/ICC/ICCtheory.pdf&quot;&gt;here&lt;/a&gt; for explanations about how to compute ICCs in R.&lt;/p&gt;</content><author><name>Brice Ozenne</name></author><summary type="html">See here for explanations about how to compute ICCs in R.</summary></entry><entry><title type="html">The 4 steps of a statistical analysis</title><link href="http://localhost:4000/jekyll/update/2018/10/26/statisticalFramework.html" rel="alternate" type="text/html" title="The 4 steps of a statistical analysis" /><published>2018-10-26T00:00:00+02:00</published><updated>2018-10-26T00:00:00+02:00</updated><id>http://localhost:4000/jekyll/update/2018/10/26/statisticalFramework</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/26/statisticalFramework.html">&lt;h2 id=&quot;phase-1-ideal-world-blinded-to-the-data&quot;&gt;Phase 1: ideal world (blinded to the data)&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Formulate the hypothesis/hypotheses to be tested.&lt;/li&gt;
  &lt;li&gt;Define the population of interest for each hypothesis.&lt;/li&gt;
  &lt;li&gt;Identify the variables/mecanisms that are related to each hypothesis:
    &lt;ul&gt;
      &lt;li&gt;outcome(s), e.g. blood pressure after 1 week.&lt;/li&gt;
      &lt;li&gt;exposure(s): e.g. therapy A vs B.&lt;/li&gt;
      &lt;li&gt;confounder(s), e.g. history of hypertension, those patients are more likely to get therapy A.&lt;/li&gt;
      &lt;li&gt;risk factor(s), e.g. BMI, therapy allocation is independent of BMI.&lt;/li&gt;
      &lt;li&gt;mediators(s): sodium intake, therapy impacts both hypertension and sodium intake (sodium intake impacts hypertension).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Draw the causal graph
&lt;br /&gt;
&lt;img src=&quot;https://bozenne.github.io/img/causalGraph.png&quot; alt=&quot;&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;What are the consequence of the design on the causal graph: &lt;br /&gt;
  e.g. randomisation of the treatment allocation would remove the link
  between Therapy and history of hypertension. &lt;br /&gt;
  e.g. a observational study could lead to have more confounders (doctor preferences could be related to Therapy and BMI). &lt;br /&gt;
  e.g. a longitudinal study would induce a correlation between the mesurements of a blood pressure for a given individual.&lt;/li&gt;
  &lt;li&gt;The statistical model (or test) you will choose should reflect:
    &lt;ul&gt;
      &lt;li&gt;the type of the outcome, e.g. binary -&amp;gt; logistic regression&lt;/li&gt;
      &lt;li&gt;the design of your data, e.g. repetead measurements -&amp;gt; mixed model&lt;/li&gt;
      &lt;li&gt;the causal graph: e.g. adjust for the possible confounders.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;phase-2-data-management&quot;&gt;Phase 2: data management&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Work on the subset of data that is relevant for your analysis. &lt;br /&gt;
e.g. in some studies, people have collected more than 200 variables but in
your study only 10 of them are relevant. Working on a smaller
dataset ease the data checking.&lt;/li&gt;
  &lt;li&gt;Identify the individuals that will be kept for the study and create
one dataset that will be used during the analysis. Drawing an
inclusion and exlcusion is usually very usefull to understand and
communicate how the individuals where selected.&lt;/li&gt;
  &lt;li&gt;Check the data that have been collected, column by column. &lt;br /&gt;
Is there extreme/abnormal values? e.g. negative times, three levels for gender: “Male”, “male”, “Female”. &lt;br /&gt;
Does the univariate distributions match what you have expected? e.g. all patients have a blood pressure &amp;gt;130 mmHg&lt;/li&gt;
  &lt;li&gt;Name your variable in english. Never use special characters.&lt;/li&gt;
  &lt;li&gt;Use explicit values and names for your variables. &lt;br /&gt; 
e.g. gender = 0,1 is not good. It should be either Male = TRUE, FALSE or Gender
= “Male”, “Female”.&lt;/li&gt;
  &lt;li&gt;Check that your data has been anonymized. You should however always keep
an identification variable (e.g. Id = “Patient_1” to Id = “Patient_52”)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;phase-3-back-to-reality&quot;&gt;Phase 3: back to reality&lt;/h2&gt;
&lt;p&gt;Considering the data that you have collected:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Does your dataset still corresponds to the population of interest?&lt;/li&gt;
  &lt;li&gt;Do you have missing values ? Is the missingness random ? Due to an
observed variable (e.g. the most diseased patients left the study) ?
Due to an unobserved variable ?&lt;/li&gt;
  &lt;li&gt;Is the number of hypotheses you want to test resonnable regarding
your sample size ?&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;phase-4-modeling-and-inference&quot;&gt;Phase 4: modeling and inference&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;Is the model define during phase 1 is still relevant?&lt;/li&gt;
  &lt;li&gt;Check model assumptions, especially linearity and
homoschedasticity. &lt;a href=&quot;jekyll/update/2017/06/23/RsoftwareRessources.html&quot;&gt;This page&lt;/a&gt; contain
some of the diagnostic functions in R.&lt;/li&gt;
  &lt;li&gt;If you had observations with extreme values, check how they impact the parameter(s) of interest.&lt;/li&gt;
  &lt;li&gt;Check the overall fit of your model. If the fit is poor then maybe
you have missed an important variable (which could be a confounder
!), or the model you used is not appropriate. This is problematic
because you are testing your hypothesis under the assumption that
the model gives an unbiased estimate of your parameter of interest.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In case of small sample sizes (n&amp;lt;50), confidence intervals based on
a gaussian approximation of the test statistic should not be
used. Confidence intervals based on a student’s t-distribution, boostrap, or
jacknife should provide a more accurate coverage.&lt;/p&gt;

    &lt;p&gt;Reporting:&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Remember to report both the effect size and the p.value. A
difference in blood pressure of 0.1mmHg may be significant (p&amp;lt;0.05)
but not clinically relevant. No need to go further. On the other
hand you could end up with a clinically relevant difference in
blood pressure (e.g. 20 mmHg) that is not clinically significant
(p&amp;gt;0.05). Maybe a larger study is necessary.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;about-variable-selection&quot;&gt;About variable selection&lt;/h2&gt;

&lt;p&gt;Most statistical software include methods to perform variable
selection. But it is often unclear whether you have a better answer to
your question after having done variable selection.&lt;/p&gt;

&lt;p&gt;“The decision on how many and which covariates to include in a model
is not at all an easy one. It is important to stress that the
interpretation of the effect of one covariate may depend strongly on
which other covariates are included in the model.” &lt;em&gt;Regression with
Linear Predictors&lt;/em&gt; (chapter 6). Per Kragh Andersen, Lene Theil
Skovgaard, 2010.&lt;/p&gt;

&lt;p&gt;Often your study is designed to test your hypothesis not to identify
possible confounders. Then you cannot expect to do a good job in
identifying the confounders using your data. Even worse, in some case
you may introduce a bias due to the selection procedure you used. This
is why, ideally, the choice of the covariates to include in the model
should be based on prior knowledge.&lt;/p&gt;</content><author><name>Brice Ozenne</name></author><summary type="html">Phase 1: ideal world (blinded to the data) Formulate the hypothesis/hypotheses to be tested. Define the population of interest for each hypothesis. Identify the variables/mecanisms that are related to each hypothesis: outcome(s), e.g. blood pressure after 1 week. exposure(s): e.g. therapy A vs B. confounder(s), e.g. history of hypertension, those patients are more likely to get therapy A. risk factor(s), e.g. BMI, therapy allocation is independent of BMI. mediators(s): sodium intake, therapy impacts both hypertension and sodium intake (sodium intake impacts hypertension). Draw the causal graph</summary></entry><entry><title type="html">Relaxing the linearity assumption using splines</title><link href="http://localhost:4000/jekyll/update/2018/10/18/Splines.html" rel="alternate" type="text/html" title="Relaxing the linearity assumption using splines" /><published>2018-10-18T00:00:00+02:00</published><updated>2018-10-18T00:00:00+02:00</updated><id>http://localhost:4000/jekyll/update/2018/10/18/Splines</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/10/18/Splines.html">&lt;p&gt;See &lt;a href=&quot;https://bozenne.github.io/doc/polynomeVSsplines/polynomeVSsplines.pdf&quot;&gt;here&lt;/a&gt; for a (very simple) example where splines are superior to polynoms to model non-linearities.&lt;/p&gt;</content><author><name>Brice Ozenne</name></author><summary type="html">See here for a (very simple) example where splines are superior to polynoms to model non-linearities.</summary></entry></feed>